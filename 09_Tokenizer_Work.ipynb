{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run Date: Saturday, January 21, 2023\n",
    "# Run Time: 00:00:29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "startTime = time.time()\n",
    "todaysDate = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only target the 2070 Super ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fjcTlyE3WvR"
   },
   "source": [
    "#Tokenizers\n",
    "Copyright 2021,2022 Denis Rothman, MIT License\n",
    "\n",
    "Reference 1 for word embedding:\n",
    "https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
    "\n",
    "Reference 2 for cosine similarity:\n",
    "SciKit Learn cosine similarity documentation\n",
    "\n",
    "***Upload text.txt before running the Notebook***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JV6bzj6-BelA"
   },
   "source": [
    "#Pre-Requisistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JKJ8Saf6vR9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Pre-Requisistes\n",
    "# !pip install gensim==3.8.3\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7o7EeDUUu0Sh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk0LxtnfBgqx"
   },
   "source": [
    "#Word2Vec Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NRomrXEJOxJ",
    "outputId": "76407b05-1c34-4bfe-e143-a78f32eaa192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=11770, vector_size=512, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "#@title Word2Vec Tokenization\n",
    "#‘text.txt’ file \n",
    "# sample = open(\"text.txt\", \"r\") \n",
    "sample = open(\"09_text.txt\", \"r\") \n",
    "s = sample.read() \n",
    "\n",
    "# processing escape characters \n",
    "f = s.replace(\"\\n\", \" \") \n",
    "\n",
    "data = [] \n",
    "# sentence parsing\n",
    "for i in sent_tokenize(f): \n",
    "\ttemp = [] \n",
    "\t# tokenize the sentence into words \n",
    "\tfor j in word_tokenize(i): \n",
    "\t\ttemp.append(j.lower())\n",
    "\tdata.append(temp)\n",
    "\n",
    "# Creating Skip Gram model \n",
    "# model2 = gensim.models.Word2Vec(data, min_count = 1, size = 512,window = 5, sg = 1) \n",
    "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 512, window = 5, sg = 1) \n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caCHjrHxBiXu"
   },
   "source": [
    "#Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YcC_3JLcJTgw"
   },
   "outputs": [],
   "source": [
    "#@title Cosine Similarity\n",
    "def similarity(word1, word2):\n",
    "        cosine=False #default value\n",
    "        try:\n",
    "                # a=model2[word1]\n",
    "                a = model2.wv[word1]\n",
    "                cosine=True\n",
    "        except KeyError:     #The KeyError exception is raised\n",
    "                print(word1, \":[unk] key not found in dictionary\")#False implied\n",
    "\n",
    "        try:\n",
    "                # b=model2[word2]#a=True implied\n",
    "                b = model2.wv[word2]#a=True implied\n",
    "        except KeyError:       #The KeyError exception is raised\n",
    "                cosine=False   #both a and b must be true\n",
    "                print(word2, \":[unk] key not found in dictionary\")\n",
    "\n",
    "        if(cosine==True):\n",
    "                # b=model2[word2]\n",
    "                b = model2.wv[word2]\n",
    "                # compute cosine similarity\n",
    "                dot = np.dot(a, b)\n",
    "                norma = np.linalg.norm(a)\n",
    "                normb = np.linalg.norm(b)\n",
    "                cos = dot / (norma * normb)\n",
    "\n",
    "                aa = a.reshape(1,512) \n",
    "                ba = b.reshape(1,512)\n",
    "                #print(\"Word1\",aa)\n",
    "                #print(\"Word2\",ba)\n",
    "                cos_lib = cosine_similarity(aa, ba)\n",
    "                #print(cos_lib,\"word similarity\")\n",
    "          \n",
    "        if(cosine==False):cos_lib=0;\n",
    "        return cos_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG8ANf4iAwqy"
   },
   "source": [
    "#Case 0: Words in the dataset and the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fMfgbogHJVh-",
    "outputId": "e63aca68-def1-4e5a-ab4f-c933e94c7e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity [[0.35858822]] freedom liberty\n"
     ]
    }
   ],
   "source": [
    "#@title Case 0: Words in text and dictionary\n",
    "word1=\"freedom\";word2=\"liberty\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpjN79c2Ay-g"
   },
   "source": [
    "#Case 1: Words not in the dataset or the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4B7vvKxOLbYC",
    "outputId": "a3371748-e482-42bb-ec6c-fba1da74a977"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corporations :[unk] key not found in dictionary\n",
      "Similarity 0 corporations rights\n"
     ]
    }
   ],
   "source": [
    "#@title Word(s) Case 1: Word not in text or dictionary\n",
    "word1=\"corporations\";word2=\"rights\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEA37lv5AuSS"
   },
   "source": [
    "#Case 2: Noisy Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkFIC79JCQJp",
    "outputId": "a3eaf824-5d9e-4e3a-ec3c-8fbf8e8e1622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity [[0.5705328]] etext declaration\n"
     ]
    }
   ],
   "source": [
    "#@title Case 2: Noisy Relationship \n",
    "word1=\"etext\";word2=\"declaration\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7Jbj4PvBKiY"
   },
   "source": [
    "#Case 3: Words in the text but not in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16uvrkFODNjv",
    "outputId": "69df8db7-138a-43a4-d365-275e8ed18dcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pie :[unk] key not found in dictionary\n",
      "Similarity 0 pie logic\n"
     ]
    }
   ],
   "source": [
    "#@title Case 3: word in text, not in dictionary\n",
    "word1=\"pie\";word2=\"logic\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-c3wayoBNSm"
   },
   "source": [
    "#Case 4: Rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKVPiEi-GZtf",
    "outputId": "69ec4009-8ec4-4892-c8a4-5489a081f961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity [[0.21750787]] justiciar judgement\n"
     ]
    }
   ],
   "source": [
    "#@title Case 4: Rare words\n",
    "word1=\"justiciar\";word2=\"judgement\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z197XkNBO07"
   },
   "source": [
    "#Case 5: Replacing rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xZtAm3DHGJg",
    "outputId": "7d70a9c7-3efa-4dab-a090-074a58b72149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity [[0.14240523]] judge judgement\n"
     ]
    }
   ],
   "source": [
    "#@title Case 5: Replacing rare words\n",
    "word1=\"judge\";word2=\"judgement\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "di4xu5j5BPGO"
   },
   "source": [
    "#Case 6: Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOSID8kXHXWt",
    "outputId": "8a8a5c75-58fb-4459-f4e7-c23fd6fee514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity [[0.516904]] pay debt\n"
     ]
    }
   ],
   "source": [
    "#@title Case 6: Entailment\n",
    "word1=\"pay\";word2=\"debt\"\n",
    "print(\"Similarity\",similarity(word1,word2),word1,word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Run Date: Saturday, January 21, 2023\n",
      "# Run Time: 00:00:29\n"
     ]
    }
   ],
   "source": [
    "endTime = time.time()\n",
    "elapsedTime = time.strftime(\"%H:%M:%S\", time.gmtime(endTime - startTime))\n",
    "\n",
    "print(todaysDate.strftime('# Run Date: %A, %B %d, %Y'))\n",
    "print(f\"# Run Time: {elapsedTime}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tokenizer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
