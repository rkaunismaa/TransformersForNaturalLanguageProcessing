{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "startTime = time.time()\n",
    "todaysDate = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only target the 2070 Super ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH2YgC7LfzJZ"
   },
   "source": [
    "#Training OpenAI GTP-2\n",
    "Copyright 2021, Denis Rothman MIT License. Denis Rothman created the Colab notebook using the OpenAI repository, adding title steps for educational purposes only.\n",
    "\n",
    "***Code References***\n",
    "\n",
    "[Reference: OpenAI Repository](https://github.com/openai/gpt-2)\n",
    "The repository was cloned and adapted to N Shepperd's repository.\n",
    "\n",
    "[Reference: N Shepperd Repository](https://github.com/nshepperd/gpt-2)\n",
    "The repository was not cloned. N Shepperd's training programs were inserted into the OpenAI Repository. The list of N Shepperd's programs are cited in the 'N Shepperd' section of the notebook. Some programs were modified for educational purposes only to work with this notebook.\n",
    "\n",
    "***Model Reference Paper***\n",
    "\n",
    "[Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,2019,'Language Models are Unsupervised Multitask Learners'](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)\n",
    "\n",
    "\n",
    "***Step 1: Pre-requisites:***\n",
    "\n",
    "a) activate GPU in the notebook settings runTime menu <br>\n",
    "b) Upload the following program files and mdset.txt(dataset) with the file manager: train.py,load_dataset.py,encode.py,accumulate,memory_saving_gradients.py,mdset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bPwOLBZsZNUI"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image     #This is used for rendering images in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIEoCIdNZPm9"
   },
   "source": [
    "#Steps 2 to 6: Initial steps of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isqdu1fpfmqM",
    "outputId": "7fad4c88-bf0d-4d74-e982-c8a058ca74b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpt-2'...\n",
      "remote: Enumerating objects: 233, done.\u001b[K\n",
      "remote: Total 233 (delta 0), reused 0 (delta 0), pack-reused 233\u001b[K\n",
      "Receiving objects: 100% (233/233), 4.38 MiB | 21.87 MiB/s, done.\n",
      "Resolving deltas: 100% (124/124), done.\n"
     ]
    }
   ],
   "source": [
    "#@title Step 2: Cloning the OpenAI GPT-2 Repository \n",
    "#!git clone https://github.com/nshepperd/gpt-2.git\n",
    "# !git clone https://github.com/openai/gpt-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RHOjN-TjUbj",
    "outputId": "638e5c41-6f69-49f1-e62a-25727bee1633"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/gpt-2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title Step 3: Installing the requirements\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m                     \u001b[38;5;66;03m# when the VM restarts import os necessary\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/content/gpt-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m    \n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip3 install -r requirements.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gpt-2'"
     ]
    }
   ],
   "source": [
    "#@title Step 3: Installing the requirements\n",
    "import os                     # when the VM restarts import os necessary\n",
    "os.chdir(\"/content/gpt-2\")    \n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9vV73Opw68m",
    "outputId": "5d0badb5-74d4-4561-ac88-deaf622c6040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting toposort\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/7d/55784e894ee0cde2474fb977ffd1651e74e840a9f92e1d847f7e3115d5ec/toposort-1.6-py2.py3-none-any.whl\n",
      "Installing collected packages: toposort\n",
      "Successfully installed toposort-1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install toposort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kpNCnh9fyYD",
    "outputId": "8c690529-0fc9-4467-ed8b-78e82afb4051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n",
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "#@title Step 4: Checking TensorFlow version \n",
    "#Colab has tf 1.x and tf 2.x installed\n",
    "#Restart runtime using 'Runtime' -> 'Restart runtime...'\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvVj0cLVkaPL",
    "outputId": "af9a9a29-6a64-43e1-e4ef-db9bd4a0117a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.00kit [00:00, 1.16Mit/s]                                                     \n",
      "Fetching encoder.json: 1.04Mit [00:00, 7.25Mit/s]                                                   \n",
      "Fetching hparams.json: 1.00kit [00:00, 1.01Mit/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:23, 21.4Mit/s]                                  \n",
      "Fetching model.ckpt.index: 6.00kit [00:00, 6.00Mit/s]                                               \n",
      "Fetching model.ckpt.meta: 472kit [00:00, 4.14Mit/s]                                                 \n",
      "Fetching vocab.bpe: 457kit [00:00, 3.47Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "#@title Step 5: Downloading 117M parameter GPT-2 Model\n",
    "# run code and send argument\n",
    "import os # after runtime is restarted\n",
    "os.chdir(\"/content/gpt-2\")\n",
    "!python3 download_model.py '117M' #creates model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV5K8rvD1b-r"
   },
   "outputs": [],
   "source": [
    "#@title Step 6: Copying the Project Resources to scr\n",
    "!cp /content/mdset.txt /content/gpt-2/src/\n",
    "!cp -r /content/gpt-2/models/ /content/gpt-2/src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqEvwSiyZXUj"
   },
   "source": [
    "#Step 7: The N Shepperd training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTUxDwtWlOLf"
   },
   "outputs": [],
   "source": [
    "#@title Step 7: Copying the N Shepperd Training Files\n",
    "#Referfence GitHub repository: https://github.com/nshepperd/gpt-2\n",
    "import os # import after runtime is restarted\n",
    "!cp /content/train.py /content/gpt-2/src/\n",
    "!cp /content/load_dataset.py /content/gpt-2/src/\n",
    "!cp /content/encode.py /content/gpt-2/src/\n",
    "!cp /content/accumulate.py /content/gpt-2/src/\n",
    "!cp /content/memory_saving_gradients.py /content/gpt-2/src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy4KSydNZfXC"
   },
   "source": [
    "#Step 8: Encoding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6T2OrWoOvG0",
    "outputId": "cb414c8c-47f5-4af0-d6ed-bf9d7fc017ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files\n",
      "100% 1/1 [00:00<00:00,  5.64it/s]\n",
      "Writing out.npz\n"
     ]
    }
   ],
   "source": [
    "#@title Step 8:Encoding dataset\n",
    "import os # import after runtime is restarted\n",
    "os.chdir(\"/content/gpt-2/src/\")\n",
    "model_name=\"117M\"\n",
    "!python /content/gpt-2/src/encode.py mdset.txt out.npz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzB5wmfxZid2"
   },
   "source": [
    "#Step 9: Training a GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "id": "jm8E-oBbZpWT",
    "outputId": "bc901e9d-0848-41ab-d606-e38be99456ef"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('https://github.com/Denis2054/Transformers-for-NLP-2nd-Edition/raw/main/Notebook%20images/AppIV/B17948_Appendix%20IV_01.PNG', width=400) #This is used for rendering images in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UzlkNGbAkDBk",
    "outputId": "5c5f7409-7c1c-4b3c-e9f4-90ec561cee00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/memory_saving_gradients.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:89: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:92: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-06-18 08:05:15.294089: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-06-18 08:05:15.294441: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f3e54d2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:05:15.294480: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-18 08:05:15.298330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-18 08:05:15.589822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:15.590619: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558f3e54dd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:05:15.590650: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-06-18 08:05:15.591624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:15.592221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-18 08:05:15.604551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:05:15.799135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-18 08:05:15.947819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-18 08:05:15.965663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-18 08:05:16.243357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-18 08:05:16.257692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-18 08:05:16.761134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-18 08:05:16.761352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:16.762102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:16.762646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-18 08:05:16.766366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:05:16.767779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-18 08:05:16.767813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-18 08:05:16.767825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-18 08:05:16.769058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:16.769725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:05:16.770313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From train.py:93: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From train.py:118: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:122: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:145: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:148: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:150: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:153: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:157: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "Loading checkpoint models/117M/model.ckpt\n",
      "Loading dataset...\n",
      "100% 1/1 [00:00<00:00, 402.99it/s]\n",
      "dataset has 29379 tokens\n",
      "Training...\n",
      "2021-06-18 08:05:41.010420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "[1 | 5.01] loss=3.20 avg=3.20\n",
      "[2 | 5.44] loss=3.40 avg=3.30\n",
      "[3 | 5.87] loss=3.01 avg=3.20\n",
      "[4 | 6.30] loss=2.51 avg=3.03\n",
      "[5 | 6.73] loss=3.25 avg=3.07\n",
      "[6 | 7.17] loss=2.47 avg=2.97\n",
      "[7 | 7.60] loss=2.83 avg=2.95\n",
      "[8 | 8.03] loss=2.87 avg=2.94\n",
      "[9 | 8.46] loss=2.88 avg=2.93\n",
      "[10 | 8.89] loss=2.82 avg=2.92\n",
      "[11 | 9.32] loss=3.07 avg=2.93\n",
      "[12 | 9.75] loss=2.97 avg=2.94\n",
      "[13 | 10.19] loss=2.28 avg=2.88\n",
      "[14 | 10.62] loss=2.93 avg=2.89\n",
      "[15 | 11.05] loss=3.09 avg=2.90\n",
      "[16 | 11.48] loss=2.91 avg=2.90\n",
      "[17 | 11.91] loss=2.18 avg=2.86\n",
      "[18 | 12.34] loss=2.74 avg=2.85\n",
      "[19 | 12.78] loss=3.70 avg=2.90\n",
      "[20 | 13.21] loss=3.33 avg=2.92\n",
      "[21 | 13.64] loss=3.01 avg=2.93\n",
      "[22 | 14.07] loss=2.26 avg=2.89\n",
      "[23 | 14.50] loss=2.03 avg=2.85\n",
      "[24 | 14.94] loss=2.14 avg=2.82\n",
      "[25 | 15.37] loss=2.62 avg=2.81\n",
      "[26 | 15.81] loss=2.83 avg=2.81\n",
      "[27 | 16.24] loss=2.33 avg=2.79\n",
      "[28 | 16.67] loss=2.69 avg=2.79\n",
      "[29 | 17.11] loss=2.75 avg=2.78\n",
      "[30 | 17.54] loss=2.73 avg=2.78\n",
      "[31 | 17.98] loss=2.80 avg=2.78\n",
      "[32 | 18.41] loss=3.49 avg=2.81\n",
      "[33 | 18.84] loss=2.85 avg=2.81\n",
      "[34 | 19.28] loss=2.66 avg=2.80\n",
      "[35 | 19.71] loss=2.37 avg=2.79\n",
      "[36 | 20.14] loss=2.89 avg=2.79\n",
      "[37 | 20.58] loss=2.41 avg=2.78\n",
      "[38 | 21.02] loss=2.76 avg=2.78\n",
      "[39 | 21.45] loss=2.89 avg=2.78\n",
      "[40 | 21.89] loss=2.93 avg=2.79\n",
      "[41 | 22.32] loss=2.68 avg=2.78\n",
      "[42 | 22.76] loss=2.62 avg=2.78\n",
      "[43 | 23.20] loss=2.89 avg=2.78\n",
      "[44 | 23.62] loss=3.50 avg=2.80\n",
      "[45 | 24.05] loss=2.86 avg=2.80\n",
      "[46 | 24.49] loss=2.58 avg=2.80\n",
      "[47 | 24.93] loss=2.71 avg=2.80\n",
      "[48 | 25.36] loss=2.14 avg=2.78\n",
      "[49 | 25.80] loss=2.49 avg=2.77\n",
      "[50 | 26.24] loss=3.13 avg=2.78\n",
      "[51 | 26.67] loss=2.80 avg=2.78\n",
      "[52 | 27.11] loss=2.65 avg=2.78\n",
      "[53 | 27.54] loss=2.39 avg=2.77\n",
      "[54 | 27.98] loss=2.36 avg=2.76\n",
      "[55 | 28.42] loss=2.78 avg=2.76\n",
      "[56 | 28.85] loss=2.49 avg=2.75\n",
      "[57 | 29.29] loss=2.12 avg=2.74\n",
      "[58 | 29.73] loss=2.20 avg=2.73\n",
      "[59 | 30.16] loss=2.22 avg=2.72\n",
      "[60 | 30.60] loss=3.52 avg=2.73\n",
      "[61 | 31.04] loss=2.65 avg=2.73\n",
      "[62 | 31.47] loss=2.49 avg=2.73\n",
      "[63 | 31.91] loss=2.47 avg=2.72\n",
      "[64 | 32.35] loss=2.37 avg=2.71\n",
      "[65 | 32.79] loss=2.55 avg=2.71\n",
      "[66 | 33.22] loss=2.68 avg=2.71\n",
      "[67 | 33.66] loss=2.52 avg=2.71\n",
      "[68 | 34.09] loss=3.33 avg=2.72\n",
      "[69 | 34.54] loss=2.52 avg=2.71\n",
      "[70 | 34.97] loss=3.24 avg=2.72\n",
      "[71 | 35.41] loss=2.36 avg=2.72\n",
      "[72 | 35.85] loss=2.37 avg=2.71\n",
      "[73 | 36.29] loss=1.95 avg=2.70\n",
      "[74 | 36.73] loss=2.48 avg=2.69\n",
      "[75 | 37.16] loss=3.06 avg=2.70\n",
      "[76 | 37.60] loss=2.34 avg=2.69\n",
      "[77 | 38.04] loss=1.77 avg=2.67\n",
      "[78 | 38.48] loss=2.50 avg=2.67\n",
      "[79 | 38.92] loss=3.04 avg=2.68\n",
      "[80 | 39.36] loss=2.46 avg=2.67\n",
      "[81 | 39.80] loss=2.49 avg=2.67\n",
      "[82 | 40.24] loss=2.30 avg=2.66\n",
      "[83 | 40.68] loss=2.56 avg=2.66\n",
      "[84 | 41.12] loss=2.23 avg=2.66\n",
      "[85 | 41.56] loss=1.92 avg=2.64\n",
      "[86 | 42.00] loss=2.25 avg=2.64\n",
      "[87 | 42.44] loss=2.33 avg=2.63\n",
      "[88 | 42.89] loss=2.21 avg=2.62\n",
      "[89 | 43.32] loss=2.27 avg=2.62\n",
      "[90 | 43.76] loss=2.48 avg=2.61\n",
      "[91 | 44.21] loss=2.12 avg=2.61\n",
      "[92 | 44.66] loss=2.11 avg=2.60\n",
      "[93 | 45.10] loss=2.18 avg=2.59\n",
      "[94 | 45.54] loss=2.02 avg=2.58\n",
      "[95 | 45.98] loss=1.78 avg=2.57\n",
      "[96 | 46.42] loss=1.65 avg=2.55\n",
      "[97 | 46.86] loss=2.01 avg=2.55\n",
      "[98 | 47.30] loss=3.04 avg=2.55\n",
      "[99 | 47.74] loss=2.58 avg=2.55\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      "q.\n",
      "(1) The first two equations (1) and (2) are the same as in (1) and (2) and the second two equations (1) and (2) are the same as in (1) and (2) and the third two equations (1) and (2) are the same as in (1) and (2) and the fourth two equations (1) and (2) are the same as in (1) and (2) and the fifth two equations (1) and (2) are the same as in (1) and (2) and the sixth two equations (1) and (2) are the same as in (1) and (2) and the seventh two equations (1) and (2) are the same as in (1) and (2) and the eighth two equations (1) and (2) are the same as in (1) and (2) and the ninth two equations (1) and (2) are the same as in (1) and (2) and the tenth two equations (1) and (2) are the same as in (1) and (2) and the eleventh two equations (1) and (2) are the same as in (1) and (2) and the twelfth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and the thirteenth two equations (1) and (2) are the same as in (1) and (2) and\n",
      "\n",
      "[100 | 60.34] loss=2.07 avg=2.55\n",
      "[101 | 60.78] loss=2.25 avg=2.54\n",
      "[102 | 61.23] loss=2.62 avg=2.54\n",
      "[103 | 61.67] loss=2.34 avg=2.54\n",
      "[104 | 62.11] loss=1.85 avg=2.53\n",
      "[105 | 62.55] loss=2.35 avg=2.53\n",
      "[106 | 63.00] loss=2.52 avg=2.53\n",
      "[107 | 63.44] loss=2.28 avg=2.52\n",
      "[108 | 63.89] loss=2.12 avg=2.52\n",
      "[109 | 64.34] loss=2.23 avg=2.51\n",
      "[110 | 64.78] loss=2.92 avg=2.52\n",
      "[111 | 65.23] loss=2.81 avg=2.52\n",
      "[112 | 65.67] loss=2.82 avg=2.53\n",
      "[113 | 66.11] loss=1.67 avg=2.51\n",
      "[114 | 66.56] loss=1.67 avg=2.50\n",
      "[115 | 67.00] loss=2.04 avg=2.50\n",
      "[116 | 67.45] loss=2.35 avg=2.49\n",
      "[117 | 67.90] loss=2.27 avg=2.49\n",
      "[118 | 68.35] loss=1.87 avg=2.48\n",
      "[119 | 68.79] loss=2.84 avg=2.49\n",
      "[120 | 69.24] loss=1.98 avg=2.48\n",
      "[121 | 69.68] loss=1.56 avg=2.47\n",
      "[122 | 70.13] loss=2.08 avg=2.46\n",
      "[123 | 70.58] loss=2.07 avg=2.45\n",
      "[124 | 71.02] loss=2.21 avg=2.45\n",
      "[125 | 71.47] loss=1.92 avg=2.44\n",
      "[126 | 71.92] loss=2.33 avg=2.44\n",
      "[127 | 72.37] loss=2.44 avg=2.44\n",
      "[128 | 72.82] loss=1.89 avg=2.43\n",
      "[129 | 73.26] loss=2.58 avg=2.44\n",
      "[130 | 73.71] loss=2.20 avg=2.43\n",
      "[131 | 74.16] loss=1.80 avg=2.42\n",
      "[132 | 74.61] loss=1.93 avg=2.42\n",
      "[133 | 75.05] loss=2.46 avg=2.42\n",
      "[134 | 75.50] loss=2.19 avg=2.42\n",
      "[135 | 75.95] loss=2.15 avg=2.41\n",
      "[136 | 76.39] loss=2.05 avg=2.41\n",
      "[137 | 76.84] loss=1.78 avg=2.40\n",
      "[138 | 77.29] loss=1.76 avg=2.39\n",
      "[139 | 77.73] loss=2.17 avg=2.39\n",
      "[140 | 78.18] loss=2.30 avg=2.39\n",
      "[141 | 78.63] loss=1.58 avg=2.38\n",
      "[142 | 79.08] loss=1.86 avg=2.37\n",
      "[143 | 79.52] loss=2.69 avg=2.37\n",
      "[144 | 79.97] loss=1.92 avg=2.37\n",
      "[145 | 80.42] loss=1.30 avg=2.35\n",
      "[146 | 80.86] loss=1.72 avg=2.34\n",
      "[147 | 81.31] loss=2.05 avg=2.34\n",
      "[148 | 81.76] loss=1.38 avg=2.33\n",
      "[149 | 82.20] loss=1.78 avg=2.32\n",
      "[150 | 82.65] loss=1.96 avg=2.32\n",
      "[151 | 83.10] loss=2.04 avg=2.31\n",
      "[152 | 83.55] loss=1.98 avg=2.31\n",
      "[153 | 83.99] loss=1.80 avg=2.30\n",
      "[154 | 84.44] loss=1.98 avg=2.30\n",
      "[155 | 84.89] loss=1.68 avg=2.29\n",
      "[156 | 85.34] loss=1.66 avg=2.28\n",
      "[157 | 85.78] loss=1.65 avg=2.27\n",
      "[158 | 86.23] loss=1.81 avg=2.27\n",
      "[159 | 86.68] loss=1.87 avg=2.26\n",
      "[160 | 87.12] loss=1.96 avg=2.26\n",
      "[161 | 87.57] loss=1.87 avg=2.26\n",
      "[162 | 88.02] loss=2.13 avg=2.25\n",
      "[163 | 88.46] loss=1.92 avg=2.25\n",
      "[164 | 88.91] loss=1.45 avg=2.24\n",
      "[165 | 89.36] loss=2.44 avg=2.24\n",
      "[166 | 89.81] loss=1.66 avg=2.23\n",
      "[167 | 90.25] loss=1.87 avg=2.23\n",
      "[168 | 90.71] loss=1.85 avg=2.23\n",
      "[169 | 91.16] loss=1.48 avg=2.22\n",
      "[170 | 91.61] loss=1.70 avg=2.21\n",
      "[171 | 92.06] loss=1.92 avg=2.21\n",
      "[172 | 92.51] loss=2.07 avg=2.21\n",
      "[173 | 92.96] loss=1.86 avg=2.20\n",
      "[174 | 93.41] loss=1.42 avg=2.19\n",
      "[175 | 93.86] loss=2.45 avg=2.19\n",
      "[176 | 94.31] loss=1.54 avg=2.19\n",
      "[177 | 94.76] loss=2.67 avg=2.19\n",
      "[178 | 95.21] loss=1.76 avg=2.19\n",
      "[179 | 95.66] loss=1.58 avg=2.18\n",
      "[180 | 96.11] loss=1.34 avg=2.17\n",
      "[181 | 96.56] loss=1.74 avg=2.17\n",
      "[182 | 97.01] loss=1.54 avg=2.16\n",
      "[183 | 97.46] loss=2.53 avg=2.16\n",
      "[184 | 97.91] loss=1.30 avg=2.15\n",
      "[185 | 98.36] loss=2.09 avg=2.15\n",
      "[186 | 98.82] loss=2.46 avg=2.15\n",
      "[187 | 99.26] loss=2.29 avg=2.16\n",
      "[188 | 99.72] loss=2.39 avg=2.16\n",
      "[189 | 100.17] loss=2.11 avg=2.16\n",
      "[190 | 100.62] loss=2.05 avg=2.16\n",
      "[191 | 101.07] loss=1.36 avg=2.15\n",
      "[192 | 101.52] loss=2.02 avg=2.15\n",
      "[193 | 101.98] loss=1.41 avg=2.14\n",
      "[194 | 102.43] loss=1.87 avg=2.13\n",
      "[195 | 102.88] loss=1.47 avg=2.13\n",
      "[196 | 103.33] loss=2.14 avg=2.13\n",
      "[197 | 103.79] loss=1.87 avg=2.12\n",
      "[198 | 104.24] loss=1.88 avg=2.12\n",
      "[199 | 104.69] loss=1.72 avg=2.12\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " H. (2005). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R. (2006). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2006). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2010). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2011). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2012). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2013a). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2013b). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2013c). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2014). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2015a). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2015b). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2015c). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2016). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2017a). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2017b). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2017c). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2018). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2019). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2020). The role of the mesenchymal domain in the regulation of cell migration. J. Biol. Chem. 277, 1036–1044.\n",
      "[Crossref]\n",
      "Berg, R., and R. J. Berg (2022). The role of the mesenchymal domain in the regulation of cell migration\n",
      "\n",
      "[200 | 115.77] loss=1.77 avg=2.11\n",
      "[201 | 116.24] loss=2.34 avg=2.11\n",
      "[202 | 116.70] loss=1.38 avg=2.11\n",
      "[203 | 117.15] loss=2.24 avg=2.11\n",
      "[204 | 117.60] loss=1.54 avg=2.10\n",
      "[205 | 118.05] loss=1.50 avg=2.09\n",
      "[206 | 118.51] loss=1.42 avg=2.09\n",
      "[207 | 118.96] loss=1.48 avg=2.08\n",
      "[208 | 119.42] loss=1.74 avg=2.08\n",
      "[209 | 119.86] loss=2.56 avg=2.08\n",
      "[210 | 120.32] loss=2.72 avg=2.09\n",
      "[211 | 120.77] loss=2.57 avg=2.09\n",
      "[212 | 121.23] loss=1.26 avg=2.08\n",
      "[213 | 121.68] loss=1.34 avg=2.08\n",
      "[214 | 122.14] loss=2.12 avg=2.08\n",
      "[215 | 122.59] loss=1.77 avg=2.07\n",
      "[216 | 123.05] loss=1.81 avg=2.07\n",
      "[217 | 123.50] loss=1.63 avg=2.07\n",
      "[218 | 123.95] loss=1.14 avg=2.06\n",
      "[219 | 124.41] loss=1.80 avg=2.05\n",
      "[220 | 124.86] loss=1.32 avg=2.04\n",
      "[221 | 125.31] loss=2.19 avg=2.05\n",
      "[222 | 125.77] loss=1.99 avg=2.05\n",
      "[223 | 126.22] loss=1.36 avg=2.04\n",
      "[224 | 126.68] loss=2.03 avg=2.04\n",
      "[225 | 127.13] loss=1.20 avg=2.03\n",
      "[226 | 127.59] loss=2.03 avg=2.03\n",
      "[227 | 128.04] loss=1.39 avg=2.02\n",
      "[228 | 128.50] loss=1.86 avg=2.02\n",
      "[229 | 128.95] loss=1.80 avg=2.02\n",
      "[230 | 129.41] loss=1.35 avg=2.01\n",
      "[231 | 129.86] loss=2.15 avg=2.01\n",
      "[232 | 130.32] loss=1.17 avg=2.00\n",
      "[233 | 130.78] loss=1.66 avg=2.00\n",
      "[234 | 131.23] loss=1.13 avg=1.99\n",
      "[235 | 131.69] loss=1.45 avg=1.98\n",
      "[236 | 132.14] loss=1.77 avg=1.98\n",
      "[237 | 132.59] loss=1.49 avg=1.97\n",
      "[238 | 133.05] loss=1.22 avg=1.97\n",
      "[239 | 133.51] loss=2.07 avg=1.97\n",
      "[240 | 133.97] loss=1.82 avg=1.97\n",
      "[241 | 134.43] loss=1.89 avg=1.96\n",
      "[242 | 134.88] loss=1.33 avg=1.96\n",
      "[243 | 135.34] loss=1.84 avg=1.96\n",
      "[244 | 135.80] loss=1.70 avg=1.95\n",
      "[245 | 136.26] loss=1.81 avg=1.95\n",
      "[246 | 136.71] loss=1.12 avg=1.94\n",
      "[247 | 137.17] loss=1.46 avg=1.94\n",
      "[248 | 137.63] loss=1.20 avg=1.93\n",
      "[249 | 138.09] loss=1.83 avg=1.93\n",
      "[250 | 138.54] loss=1.50 avg=1.92\n",
      "[251 | 139.00] loss=2.02 avg=1.93\n",
      "[252 | 139.45] loss=1.42 avg=1.92\n",
      "[253 | 139.91] loss=1.07 avg=1.91\n",
      "[254 | 140.36] loss=1.95 avg=1.91\n",
      "[255 | 140.82] loss=2.03 avg=1.91\n",
      "[256 | 141.28] loss=1.97 avg=1.91\n",
      "[257 | 141.74] loss=1.00 avg=1.90\n",
      "[258 | 142.19] loss=1.63 avg=1.90\n",
      "[259 | 142.65] loss=2.02 avg=1.90\n",
      "[260 | 143.11] loss=1.64 avg=1.90\n",
      "[261 | 143.57] loss=1.50 avg=1.89\n",
      "[262 | 144.03] loss=1.67 avg=1.89\n",
      "[263 | 144.49] loss=1.34 avg=1.89\n",
      "[264 | 144.95] loss=1.78 avg=1.88\n",
      "[265 | 145.40] loss=1.71 avg=1.88\n",
      "[266 | 145.86] loss=1.85 avg=1.88\n",
      "[267 | 146.31] loss=1.41 avg=1.88\n",
      "[268 | 146.78] loss=1.26 avg=1.87\n",
      "[269 | 147.24] loss=1.46 avg=1.87\n",
      "[270 | 147.69] loss=1.38 avg=1.86\n",
      "[271 | 148.15] loss=1.41 avg=1.86\n",
      "[272 | 148.61] loss=1.35 avg=1.85\n",
      "[273 | 149.07] loss=1.62 avg=1.85\n",
      "[274 | 149.53] loss=1.34 avg=1.84\n",
      "[275 | 149.99] loss=1.77 avg=1.84\n",
      "[276 | 150.45] loss=1.49 avg=1.84\n",
      "[277 | 150.91] loss=1.71 avg=1.84\n",
      "[278 | 151.37] loss=1.42 avg=1.83\n",
      "[279 | 151.83] loss=2.36 avg=1.84\n",
      "[280 | 152.28] loss=1.18 avg=1.83\n",
      "[281 | 152.74] loss=1.44 avg=1.83\n",
      "[282 | 153.20] loss=0.79 avg=1.82\n",
      "[283 | 153.66] loss=1.48 avg=1.81\n",
      "[284 | 154.12] loss=0.96 avg=1.80\n",
      "[285 | 154.58] loss=1.63 avg=1.80\n",
      "[286 | 155.04] loss=1.56 avg=1.80\n",
      "[287 | 155.50] loss=1.25 avg=1.79\n",
      "[288 | 155.96] loss=1.07 avg=1.79\n",
      "[289 | 156.42] loss=1.71 avg=1.78\n",
      "[290 | 156.88] loss=0.92 avg=1.78\n",
      "[291 | 157.34] loss=0.87 avg=1.77\n",
      "[292 | 157.80] loss=2.04 avg=1.77\n",
      "[293 | 158.26] loss=1.30 avg=1.76\n",
      "[294 | 158.72] loss=1.58 avg=1.76\n",
      "[295 | 159.18] loss=1.64 avg=1.76\n",
      "[296 | 159.64] loss=1.43 avg=1.76\n",
      "[297 | 160.10] loss=1.12 avg=1.75\n",
      "[298 | 160.57] loss=1.25 avg=1.75\n",
      "[299 | 161.03] loss=1.84 avg=1.75\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      ")\n",
      "and the mean velocity\n",
      "S = mS\n",
      "The mean velocity is the mean velocity of the cells\n",
      "λ =\n",
      "1\n",
      "for all the\n",
      "S\n",
      "and\n",
      "λ =\n",
      "1\n",
      "for all the\n",
      "ρ\n",
      "\n",
      "and\n",
      "ρ =\n",
      "\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "\n",
      "cos(ξ) =\n",
      "1\n",
      "for all the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ",\n",
      "the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "and\n",
      "∂τ\n",
      "S\n",
      ", the mean velocity is the mean velocity of the cells\n",
      "ρ\n",
      " =\n",
      "0\n",
      ".\n",
      "In particular, the\n",
      "∂τ\n",
      "S\n",
      "\n",
      "\n",
      "[300 | 172.13] loss=1.21 avg=1.74\n",
      "[301 | 172.62] loss=0.88 avg=1.73\n",
      "[302 | 173.08] loss=1.03 avg=1.72\n",
      "[303 | 173.54] loss=0.93 avg=1.72\n",
      "[304 | 174.00] loss=1.62 avg=1.72\n",
      "[305 | 174.46] loss=0.98 avg=1.71\n",
      "[306 | 174.93] loss=1.52 avg=1.71\n",
      "[307 | 175.39] loss=0.98 avg=1.70\n",
      "[308 | 175.85] loss=0.92 avg=1.69\n",
      "[309 | 176.31] loss=1.15 avg=1.68\n",
      "[310 | 176.77] loss=1.02 avg=1.68\n",
      "[311 | 177.24] loss=1.13 avg=1.67\n",
      "[312 | 177.70] loss=1.04 avg=1.66\n",
      "[313 | 178.17] loss=1.10 avg=1.66\n",
      "[314 | 178.63] loss=1.08 avg=1.65\n",
      "[315 | 179.10] loss=0.77 avg=1.64\n",
      "[316 | 179.56] loss=2.05 avg=1.65\n",
      "[317 | 180.02] loss=0.71 avg=1.64\n",
      "[318 | 180.48] loss=1.82 avg=1.64\n",
      "[319 | 180.94] loss=2.07 avg=1.64\n",
      "[320 | 181.41] loss=1.22 avg=1.64\n",
      "[321 | 181.87] loss=0.85 avg=1.63\n",
      "[322 | 182.34] loss=1.98 avg=1.64\n",
      "[323 | 182.81] loss=2.61 avg=1.65\n",
      "[324 | 183.27] loss=1.42 avg=1.64\n",
      "[325 | 183.74] loss=0.88 avg=1.64\n",
      "[326 | 184.20] loss=1.20 avg=1.63\n",
      "[327 | 184.66] loss=1.30 avg=1.63\n",
      "[328 | 185.13] loss=0.55 avg=1.62\n",
      "[329 | 185.59] loss=1.46 avg=1.61\n",
      "[330 | 186.05] loss=1.41 avg=1.61\n",
      "[331 | 186.52] loss=1.23 avg=1.61\n",
      "[332 | 186.98] loss=1.48 avg=1.61\n",
      "[333 | 187.45] loss=1.20 avg=1.60\n",
      "[334 | 187.91] loss=0.54 avg=1.59\n",
      "[335 | 188.38] loss=1.13 avg=1.59\n",
      "[336 | 188.84] loss=1.47 avg=1.59\n",
      "[337 | 189.30] loss=1.15 avg=1.58\n",
      "[338 | 189.77] loss=1.72 avg=1.58\n",
      "[339 | 190.24] loss=0.68 avg=1.57\n",
      "[340 | 190.70] loss=0.77 avg=1.57\n",
      "[341 | 191.17] loss=0.63 avg=1.56\n",
      "[342 | 191.63] loss=0.97 avg=1.55\n",
      "[343 | 192.10] loss=0.64 avg=1.54\n",
      "[344 | 192.56] loss=0.74 avg=1.53\n",
      "[345 | 193.02] loss=1.67 avg=1.53\n",
      "[346 | 193.49] loss=1.62 avg=1.53\n",
      "[347 | 193.95] loss=0.97 avg=1.53\n",
      "[348 | 194.42] loss=0.74 avg=1.52\n",
      "[349 | 194.89] loss=1.15 avg=1.52\n",
      "[350 | 195.35] loss=1.48 avg=1.52\n",
      "[351 | 195.82] loss=0.67 avg=1.51\n",
      "[352 | 196.29] loss=1.69 avg=1.51\n",
      "[353 | 196.76] loss=1.36 avg=1.51\n",
      "[354 | 197.22] loss=0.77 avg=1.50\n",
      "[355 | 197.69] loss=0.90 avg=1.49\n",
      "[356 | 198.16] loss=0.69 avg=1.49\n",
      "[357 | 198.62] loss=1.43 avg=1.48\n",
      "[358 | 199.09] loss=1.01 avg=1.48\n",
      "[359 | 199.56] loss=0.74 avg=1.47\n",
      "[360 | 200.03] loss=0.90 avg=1.47\n",
      "[361 | 200.49] loss=0.51 avg=1.46\n",
      "[362 | 200.96] loss=1.14 avg=1.45\n",
      "[363 | 201.43] loss=0.81 avg=1.45\n",
      "[364 | 201.89] loss=1.15 avg=1.44\n",
      "[365 | 202.36] loss=1.32 avg=1.44\n",
      "[366 | 202.82] loss=1.14 avg=1.44\n",
      "[367 | 203.28] loss=1.40 avg=1.44\n",
      "[368 | 203.75] loss=1.64 avg=1.44\n",
      "[369 | 204.21] loss=0.80 avg=1.43\n",
      "[370 | 204.68] loss=1.10 avg=1.43\n",
      "[371 | 205.15] loss=0.71 avg=1.42\n",
      "[372 | 205.61] loss=1.82 avg=1.43\n",
      "[373 | 206.08] loss=0.80 avg=1.42\n",
      "[374 | 206.55] loss=0.50 avg=1.41\n",
      "[375 | 207.02] loss=1.06 avg=1.41\n",
      "[376 | 207.48] loss=1.06 avg=1.40\n",
      "[377 | 207.95] loss=0.94 avg=1.40\n",
      "[378 | 208.42] loss=1.28 avg=1.40\n",
      "[379 | 208.89] loss=1.47 avg=1.40\n",
      "[380 | 209.35] loss=0.63 avg=1.39\n",
      "[381 | 209.82] loss=0.74 avg=1.39\n",
      "[382 | 210.29] loss=1.00 avg=1.38\n",
      "[383 | 210.75] loss=1.01 avg=1.38\n",
      "[384 | 211.22] loss=0.59 avg=1.37\n",
      "[385 | 211.69] loss=0.42 avg=1.36\n",
      "[386 | 212.16] loss=0.96 avg=1.36\n",
      "[387 | 212.63] loss=1.30 avg=1.36\n",
      "[388 | 213.09] loss=0.82 avg=1.35\n",
      "[389 | 213.56] loss=1.89 avg=1.36\n",
      "[390 | 214.02] loss=1.59 avg=1.36\n",
      "[391 | 214.49] loss=1.30 avg=1.36\n",
      "[392 | 214.96] loss=0.74 avg=1.35\n",
      "[393 | 215.43] loss=0.76 avg=1.34\n",
      "[394 | 215.89] loss=0.52 avg=1.34\n",
      "[395 | 216.36] loss=1.50 avg=1.34\n",
      "[396 | 216.83] loss=0.71 avg=1.33\n",
      "[397 | 217.30] loss=1.12 avg=1.33\n",
      "[398 | 217.77] loss=1.43 avg=1.33\n",
      "[399 | 218.23] loss=0.94 avg=1.33\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " randomly, we can perform a linear\n",
      "weighting of the variance of the distribution function q. We shall now consider the\n",
      "case in which q is a non-local variable and the choice of a non-local\n",
      "variable is not a non-local choice. In this case, we shall consider the\n",
      "case in which q is a non-local variable and the choice of q is not a non-local variable.\n",
      "In this case, we shall choose the non-local variable q as the non-local variable.\n",
      "In the next sections, we shall analyze the two-dimensional case in which the choice of\n",
      "q is not a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which the\n",
      "choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in which\n",
      "the choice is a non-local choice.\n",
      "In the next sections, we shall analyze the non-local variable choice in the case in\n",
      "\n",
      "[400 | 229.37] loss=0.43 avg=1.32\n",
      "[401 | 229.86] loss=0.46 avg=1.31\n",
      "[402 | 230.33] loss=0.74 avg=1.30\n",
      "[403 | 230.79] loss=0.77 avg=1.30\n",
      "[404 | 231.26] loss=0.88 avg=1.29\n",
      "[405 | 231.72] loss=0.85 avg=1.29\n",
      "[406 | 232.19] loss=1.23 avg=1.29\n",
      "[407 | 232.65] loss=1.15 avg=1.29\n",
      "[408 | 233.12] loss=0.78 avg=1.28\n",
      "[409 | 233.59] loss=0.89 avg=1.28\n",
      "[410 | 234.06] loss=0.85 avg=1.27\n",
      "[411 | 234.52] loss=0.76 avg=1.27\n",
      "[412 | 234.99] loss=0.67 avg=1.26\n",
      "[413 | 235.46] loss=0.42 avg=1.25\n",
      "[414 | 235.93] loss=1.02 avg=1.25\n",
      "[415 | 236.39] loss=0.94 avg=1.25\n",
      "[416 | 236.86] loss=0.29 avg=1.24\n",
      "[417 | 237.32] loss=0.59 avg=1.23\n",
      "[418 | 237.79] loss=0.55 avg=1.22\n",
      "[419 | 238.26] loss=1.47 avg=1.23\n",
      "[420 | 238.73] loss=0.56 avg=1.22\n",
      "[421 | 239.20] loss=0.49 avg=1.21\n",
      "[422 | 239.67] loss=1.01 avg=1.21\n",
      "[423 | 240.13] loss=0.96 avg=1.21\n",
      "[424 | 240.61] loss=0.96 avg=1.21\n",
      "[425 | 241.07] loss=1.06 avg=1.20\n",
      "[426 | 241.53] loss=1.30 avg=1.21\n",
      "[427 | 242.00] loss=0.60 avg=1.20\n",
      "[428 | 242.47] loss=0.46 avg=1.19\n",
      "[429 | 242.94] loss=1.57 avg=1.20\n",
      "[430 | 243.40] loss=1.19 avg=1.20\n",
      "[431 | 243.87] loss=0.60 avg=1.19\n",
      "[432 | 244.34] loss=0.54 avg=1.18\n",
      "[433 | 244.80] loss=0.86 avg=1.18\n",
      "[434 | 245.27] loss=1.24 avg=1.18\n",
      "[435 | 245.74] loss=0.49 avg=1.17\n",
      "[436 | 246.20] loss=0.48 avg=1.17\n",
      "[437 | 246.67] loss=0.25 avg=1.16\n",
      "[438 | 247.14] loss=0.41 avg=1.15\n",
      "[439 | 247.61] loss=0.84 avg=1.15\n",
      "[440 | 248.08] loss=0.84 avg=1.14\n",
      "[441 | 248.54] loss=0.51 avg=1.14\n",
      "[442 | 249.01] loss=0.71 avg=1.13\n",
      "[443 | 249.48] loss=0.70 avg=1.13\n",
      "[444 | 249.94] loss=1.53 avg=1.13\n",
      "[445 | 250.41] loss=0.44 avg=1.12\n",
      "[446 | 250.88] loss=1.08 avg=1.12\n",
      "[447 | 251.34] loss=0.44 avg=1.12\n",
      "[448 | 251.81] loss=0.60 avg=1.11\n",
      "[449 | 252.28] loss=0.84 avg=1.11\n",
      "[450 | 252.75] loss=0.79 avg=1.11\n",
      "[451 | 253.22] loss=1.36 avg=1.11\n",
      "[452 | 253.68] loss=0.81 avg=1.11\n",
      "[453 | 254.15] loss=0.95 avg=1.10\n",
      "[454 | 254.61] loss=0.94 avg=1.10\n",
      "[455 | 255.08] loss=0.47 avg=1.10\n",
      "[456 | 255.55] loss=0.75 avg=1.09\n",
      "[457 | 256.01] loss=0.74 avg=1.09\n",
      "[458 | 256.48] loss=0.24 avg=1.08\n",
      "[459 | 256.95] loss=0.31 avg=1.07\n",
      "[460 | 257.41] loss=0.74 avg=1.07\n",
      "[461 | 257.88] loss=0.61 avg=1.06\n",
      "[462 | 258.35] loss=0.41 avg=1.06\n",
      "[463 | 258.81] loss=0.25 avg=1.05\n",
      "[464 | 259.28] loss=0.70 avg=1.05\n",
      "[465 | 259.75] loss=0.31 avg=1.04\n",
      "[466 | 260.22] loss=0.81 avg=1.04\n",
      "[467 | 260.69] loss=0.42 avg=1.03\n",
      "[468 | 261.15] loss=0.20 avg=1.02\n",
      "[469 | 261.62] loss=1.49 avg=1.03\n",
      "[470 | 262.09] loss=1.16 avg=1.03\n",
      "[471 | 262.55] loss=0.42 avg=1.02\n",
      "[472 | 263.02] loss=1.13 avg=1.02\n",
      "[473 | 263.49] loss=0.35 avg=1.02\n",
      "[474 | 263.96] loss=1.14 avg=1.02\n",
      "[475 | 264.42] loss=0.29 avg=1.01\n",
      "[476 | 264.89] loss=0.41 avg=1.00\n",
      "[477 | 265.36] loss=1.04 avg=1.00\n",
      "[478 | 265.82] loss=0.89 avg=1.00\n",
      "[479 | 266.29] loss=0.74 avg=1.00\n",
      "[480 | 266.76] loss=1.07 avg=1.00\n",
      "[481 | 267.23] loss=0.68 avg=1.00\n",
      "[482 | 267.69] loss=0.51 avg=0.99\n",
      "[483 | 268.16] loss=0.69 avg=0.99\n",
      "[484 | 268.63] loss=0.73 avg=0.99\n",
      "[485 | 269.09] loss=0.80 avg=0.99\n",
      "[486 | 269.56] loss=0.84 avg=0.98\n",
      "[487 | 270.02] loss=0.67 avg=0.98\n",
      "[488 | 270.49] loss=0.68 avg=0.98\n",
      "[489 | 270.96] loss=0.36 avg=0.97\n",
      "[490 | 271.43] loss=0.31 avg=0.97\n",
      "[491 | 271.89] loss=1.33 avg=0.97\n",
      "[492 | 272.36] loss=0.87 avg=0.97\n",
      "[493 | 272.83] loss=0.59 avg=0.96\n",
      "[494 | 273.30] loss=0.97 avg=0.96\n",
      "[495 | 273.77] loss=0.75 avg=0.96\n",
      "[496 | 274.23] loss=0.57 avg=0.96\n",
      "[497 | 274.70] loss=0.53 avg=0.95\n",
      "[498 | 275.17] loss=0.27 avg=0.95\n",
      "[499 | 275.63] loss=0.65 avg=0.94\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " might be related to the degree of alignment of the fibers.\n",
      "4.1.1.1. Linear models\n",
      "We shall consider two different representations of the linear equations describing the evolution of\n",
      "the distribution of the senses of the sense. In particular, we shall consider the\n",
      "models Dq and S. The model class γq represents the casein\n",
      "vector of the individuals of haptoglobin A 1c , and it is given by\n",
      "pi\n",
      "(x, vˆ) =\n",
      "0\n",
      "4πI0(ξ)\n",
      "4πI1(ξ)\n",
      "4π\n",
      "I\n",
      "k(x)\n",
      "4π\n",
      "Ik(ξ)\n",
      "\n",
      "where I = the number of homeodimers of the cell\n",
      "k = the speed\n",
      "∇ · vˆ\n",
      ", that gives the numerical resolution\n",
      "∇S\n",
      "S =\n",
      "vˆMq\n",
      "x\n",
      "2\n",
      "pi\n",
      "(ξ)\n",
      "=\n",
      "ξ\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k =\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "I\n",
      "k =\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "I\n",
      "4πI0(ξ)\n",
      "4πI1(ξ)\n",
      "4πI1\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "=\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "I\n",
      "k\n",
      "2\n",
      "pi\n",
      "(ξ)\n",
      "=\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "2\n",
      "k=\n",
      "I\n",
      "k\n",
      "2\n",
      "cos(ξ)\n",
      "2\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "2\n",
      "pi\n",
      "(ξ)\n",
      "=\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "2\n",
      "k=\n",
      "I\n",
      "k\n",
      "2\n",
      "trans\n",
      "2\n",
      "k(ξ)\n",
      "2\n",
      "difference\n",
      "2\n",
      "k(ξ)\n",
      "2\n",
      "∇\n",
      "I\n",
      "k\n",
      "k\n",
      "\n",
      "2\n",
      "difference\n",
      "k(ξ)\n",
      "2\n",
      "∇ · vˆ\n",
      "\n",
      "I\n",
      "k\n",
      "2\n",
      "difference\n",
      "{\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "0\n",
      "k\n",
      "(ξ)\n",
      "\n",
      "=\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "0\n",
      "k\n",
      "(ξ)\n",
      "=\n",
      "I\n",
      "k\n",
      "2\n",
      "difference\n",
      "k(ξ)\n",
      "2\n",
      "difference\n",
      "=\n",
      "\n",
      "I\n",
      "k\n",
      "2\n",
      "difference\n",
      "{\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "0\n",
      "k\n",
      "(ξ)\n",
      "\n",
      "=\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "2\n",
      "difference\n",
      "k(ξ)\n",
      "2\n",
      "difference\n",
      "=\n",
      "I\n",
      "k\n",
      "2\n",
      "difference\n",
      "{\n",
      "Γ\n",
      "Ik\n",
      "k\n",
      "k\n",
      "0\n",
      "k\n",
      "(ξ)\n",
      "   \n",
      "k\n",
      "2\n",
      "difference\n",
      "}\n",
      "}\n",
      "2\n",
      "lke(Γ, vˆ)\n",
      "4πI0(ξ)\n",
      "4πI1(ξ)\n",
      "4πI1(ξ)\n",
      "I\n",
      "lk(Γ, vˆ)\n",
      "4\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "lk(Γ)\n",
      "||(\n",
      "I\n",
      "lk(Γ)\n",
      "||\n",
      "I\n",
      "lk(Γ)\n",
      "=\n",
      "I\n",
      "\n",
      "\n",
      "[500 | 286.81] loss=0.60 avg=0.94\n",
      "[501 | 287.30] loss=0.28 avg=0.93\n",
      "[502 | 287.76] loss=1.06 avg=0.94\n",
      "[503 | 288.24] loss=0.33 avg=0.93\n",
      "[504 | 288.71] loss=0.92 avg=0.93\n",
      "[505 | 289.17] loss=0.33 avg=0.92\n",
      "[506 | 289.64] loss=0.24 avg=0.92\n",
      "[507 | 290.11] loss=0.98 avg=0.92\n",
      "[508 | 290.58] loss=0.51 avg=0.91\n",
      "[509 | 291.04] loss=0.77 avg=0.91\n",
      "[510 | 291.51] loss=0.75 avg=0.91\n",
      "[511 | 291.98] loss=0.48 avg=0.91\n",
      "[512 | 292.45] loss=1.05 avg=0.91\n",
      "[513 | 292.92] loss=3.15 avg=0.93\n",
      "[514 | 293.38] loss=0.51 avg=0.92\n",
      "[515 | 293.85] loss=0.46 avg=0.92\n",
      "[516 | 294.32] loss=0.61 avg=0.92\n",
      "[517 | 294.79] loss=0.27 avg=0.91\n",
      "[518 | 295.26] loss=0.50 avg=0.91\n",
      "[519 | 295.72] loss=1.97 avg=0.92\n",
      "[520 | 296.19] loss=0.50 avg=0.91\n",
      "[521 | 296.66] loss=0.59 avg=0.91\n",
      "[522 | 297.13] loss=0.18 avg=0.90\n",
      "[523 | 297.60] loss=0.55 avg=0.90\n",
      "[524 | 298.06] loss=0.62 avg=0.90\n",
      "[525 | 298.53] loss=0.81 avg=0.90\n",
      "[526 | 299.00] loss=0.35 avg=0.89\n",
      "[527 | 299.47] loss=1.84 avg=0.90\n",
      "[528 | 299.94] loss=0.29 avg=0.89\n",
      "[529 | 300.41] loss=0.40 avg=0.89\n",
      "[530 | 300.87] loss=0.38 avg=0.88\n",
      "[531 | 301.34] loss=0.61 avg=0.88\n",
      "[532 | 301.81] loss=0.38 avg=0.88\n",
      "[533 | 302.28] loss=0.38 avg=0.87\n",
      "[534 | 302.75] loss=0.45 avg=0.87\n",
      "[535 | 303.22] loss=0.34 avg=0.86\n",
      "[536 | 303.69] loss=0.68 avg=0.86\n",
      "[537 | 304.16] loss=1.83 avg=0.87\n",
      "[538 | 304.63] loss=0.80 avg=0.87\n",
      "[539 | 305.10] loss=1.97 avg=0.88\n",
      "[540 | 305.57] loss=0.44 avg=0.88\n",
      "[541 | 306.03] loss=0.17 avg=0.87\n",
      "[542 | 306.50] loss=0.75 avg=0.87\n",
      "[543 | 306.97] loss=0.95 avg=0.87\n",
      "[544 | 307.44] loss=0.55 avg=0.86\n",
      "[545 | 307.91] loss=0.31 avg=0.86\n",
      "[546 | 308.38] loss=0.49 avg=0.86\n",
      "[547 | 308.85] loss=0.22 avg=0.85\n",
      "[548 | 309.32] loss=0.42 avg=0.84\n",
      "[549 | 309.79] loss=0.31 avg=0.84\n",
      "[550 | 310.26] loss=0.84 avg=0.84\n",
      "[551 | 310.73] loss=2.04 avg=0.85\n",
      "[552 | 311.20] loss=0.39 avg=0.85\n",
      "[553 | 311.67] loss=0.23 avg=0.84\n",
      "[554 | 312.14] loss=0.38 avg=0.84\n",
      "[555 | 312.62] loss=0.22 avg=0.83\n",
      "[556 | 313.09] loss=0.30 avg=0.82\n",
      "[557 | 313.56] loss=0.22 avg=0.82\n",
      "[558 | 314.03] loss=0.25 avg=0.81\n",
      "[559 | 314.50] loss=0.68 avg=0.81\n",
      "[560 | 314.97] loss=0.97 avg=0.81\n",
      "[561 | 315.44] loss=0.20 avg=0.81\n",
      "[562 | 315.91] loss=0.19 avg=0.80\n",
      "[563 | 316.38] loss=0.96 avg=0.80\n",
      "[564 | 316.85] loss=0.35 avg=0.80\n",
      "[565 | 317.34] loss=0.61 avg=0.80\n",
      "[566 | 317.81] loss=0.32 avg=0.79\n",
      "[567 | 318.28] loss=0.28 avg=0.79\n",
      "[568 | 318.75] loss=0.52 avg=0.78\n",
      "[569 | 319.23] loss=0.34 avg=0.78\n",
      "[570 | 319.70] loss=0.86 avg=0.78\n",
      "[571 | 320.17] loss=0.83 avg=0.78\n",
      "[572 | 320.64] loss=0.40 avg=0.78\n",
      "[573 | 321.11] loss=0.73 avg=0.78\n",
      "[574 | 321.58] loss=0.21 avg=0.77\n",
      "[575 | 322.05] loss=0.38 avg=0.77\n",
      "[576 | 322.52] loss=0.64 avg=0.76\n",
      "[577 | 322.99] loss=0.20 avg=0.76\n",
      "[578 | 323.46] loss=0.17 avg=0.75\n",
      "[579 | 323.92] loss=1.18 avg=0.76\n",
      "[580 | 324.39] loss=0.68 avg=0.76\n",
      "[581 | 324.86] loss=0.26 avg=0.75\n",
      "[582 | 325.33] loss=1.29 avg=0.76\n",
      "[583 | 325.80] loss=0.63 avg=0.76\n",
      "[584 | 326.27] loss=0.52 avg=0.75\n",
      "[585 | 326.74] loss=1.52 avg=0.76\n",
      "[586 | 327.21] loss=0.54 avg=0.76\n",
      "[587 | 327.68] loss=0.22 avg=0.75\n",
      "[588 | 328.15] loss=1.12 avg=0.76\n",
      "[589 | 328.63] loss=0.48 avg=0.75\n",
      "[590 | 329.10] loss=0.35 avg=0.75\n",
      "[591 | 329.56] loss=0.21 avg=0.74\n",
      "[592 | 330.03] loss=0.54 avg=0.74\n",
      "[593 | 330.51] loss=0.43 avg=0.74\n",
      "[594 | 330.98] loss=0.15 avg=0.73\n",
      "[595 | 331.45] loss=0.52 avg=0.73\n",
      "[596 | 331.92] loss=0.17 avg=0.73\n",
      "[597 | 332.39] loss=0.13 avg=0.72\n",
      "[598 | 332.86] loss=0.19 avg=0.71\n",
      "[599 | 333.33] loss=0.51 avg=0.71\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " order of the fibers network.\n",
      "The fibers network consists of a double-edged sword. If one reads the code as\n",
      "[36]\n",
      "n > 0, the possible outcomes are\n",
      "1) ηS = λ ≤ 1, ηq = λ ≤ 1, and\n",
      "2) ηS + ηq = λ ≤ 1.\n",
      "In the latter case, the macroscopic limit is not large enough, and the\n",
      "transition probability is not large enough to capture the macroscopic expansion of the cell population\n",
      "at the macroscopic level. Therefore, we perform\n",
      "a diffusion tensor\n",
      "DICT=ξ\n",
      "k(x, v, vˆ)vˆ (32)\n",
      "that represents the diffusion tensor of the fibers distributed along the fibers cluster.\n",
      "5\n",
      "2.2 Amoeboid motion and chemotaxis\n",
      "We now want to obtain a macroscopic motion in which the fibers are directed\n",
      "at an underlying chemoattractant. In particular, we shall consider a\n",
      "chemoattractant S(x, v, vˆ) = µ, that represents a point in space where the\n",
      "chemoattractant's directions are aligned. Therefore, we shall consider the\n",
      "chemoattractant's average velocities (λ/z, v, vˆ) = θq(x, v, vˆ), that represents the average\n",
      "length of the fibers driven ∼q. The mean velocity (S,vˆ) = 100000, that represents the average\n",
      "time since the point of closest alignment (zero to the direction of alignment), that represents the alignment\n",
      "imposed by the most recent alignment. The second parameter (λ) determines the microscopic velocity, that\n",
      "corresponds to the in (0.02, 0.5)neq(ξ), i.e., the microscopic velocity is the product of\n",
      "the macroscopic value and the diagonal (0, 0.5) of the Sine, that corresponds to the macroscopic\n",
      "offset.\n",
      "(a) Fibers distribution. (b) Schematic of the first distribution given in (c).\n",
      "(c) t=1.25 (d) t=2.5 (e) t=5 (f) t=6.25\n",
      "(g) t=1.25 (h) t=2.5 (i) t=5 (j) t=6.25\n",
      "Figure 3: Test 2 Case i) with non-local ECM image and chemiluminescence global positioning system (CSS), using the nearest neighbor system determined by the\n",
      "variance of the fibers distribution. The chemoattractant has a double bias due to it not sensing the fibers in\n",
      "the neighborhood of S, thus increasing the accuracy of the run-in with fibers analysis). The sensing radius R is\n",
      "t(R,S)-(lS) = 0.8. The Sine of the chemoattractant's yaw operator is defined as\n",
      "UT (ξ) = Z\n",
      "S (at pickup kHz)d−1. Setting the bias to zero, the cell can perform a\n",
      "microscopic drift-jump\n",
      "Figure 4: Test 3 Case ii) with non-local ECM image and SPSS-Caltech SPSS-Lab, using a Bessel function\n",
      "sensing-domain as used in (see Fig. 3d). The sensing radius R\n",
      "is t(R,S)-(lS) = 0.8. Setting the bias to zero, the cell can perform a\n",
      "microscopic drift-jump\n",
      "Figure 5: Test 4 Case iii) with non-local ECM image and Siemens DeltaIoB, using a Bessel function\n",
      "sensing-domain as used in (see Fig. 5d). The sensing radius R\n",
      "is t(R,S)-(lS) = 0.8. Setting the bias to zero, the cell can perform a\n",
      "microscopic drift-jump\n",
      "Figure 6: Test 5 ii) with non-local ECM image and Siemens DeltaIoB, using a Bessel function\n",
      "sensing-domain as used in (see Fig. 5e): the sensing radius R\n",
      "is t(R,S)-(lS) = 0.8. Setting the bias to zero, the cell can perform a\n",
      "microscopic drift-jump\n",
      "Figure 7: Test 6 iii) with non-local ECM image and Siemens DeltaIoB, using a Bessel function\n",
      "sensing-domain as used in (see Fig. 5f). The sensing radius R\n",
      "is t(R,S)-(lS) = 0.8. Setting the bias to zero, the cell can perform a\n",
      "microscopic drift-jump\n",
      "Figure 8: Test 5 iv) with non-local ECM image and Siemens\n",
      "\n",
      "[600 | 344.37] loss=0.47 avg=0.71\n",
      "[601 | 344.86] loss=1.18 avg=0.71\n",
      "[602 | 345.32] loss=0.19 avg=0.71\n",
      "[603 | 345.80] loss=0.25 avg=0.71\n",
      "[604 | 346.27] loss=0.43 avg=0.70\n",
      "[605 | 346.74] loss=0.42 avg=0.70\n",
      "[606 | 347.21] loss=0.48 avg=0.70\n",
      "[607 | 347.69] loss=0.40 avg=0.69\n",
      "[608 | 348.17] loss=0.20 avg=0.69\n",
      "[609 | 348.63] loss=0.32 avg=0.69\n",
      "[610 | 349.11] loss=0.38 avg=0.68\n",
      "[611 | 349.58] loss=0.31 avg=0.68\n",
      "[612 | 350.05] loss=0.45 avg=0.68\n",
      "[613 | 350.52] loss=0.19 avg=0.67\n",
      "[614 | 350.99] loss=0.32 avg=0.67\n",
      "[615 | 351.47] loss=0.72 avg=0.67\n",
      "[616 | 351.94] loss=0.46 avg=0.67\n",
      "[617 | 352.41] loss=0.25 avg=0.66\n",
      "[618 | 352.88] loss=0.33 avg=0.66\n",
      "[619 | 353.35] loss=0.33 avg=0.66\n",
      "[620 | 353.82] loss=0.39 avg=0.65\n",
      "[621 | 354.29] loss=0.43 avg=0.65\n",
      "[622 | 354.76] loss=1.04 avg=0.65\n",
      "[623 | 355.24] loss=0.24 avg=0.65\n",
      "[624 | 355.71] loss=0.29 avg=0.65\n",
      "[625 | 356.18] loss=0.33 avg=0.64\n",
      "[626 | 356.64] loss=0.30 avg=0.64\n",
      "[627 | 357.12] loss=0.12 avg=0.64\n",
      "[628 | 357.59] loss=0.52 avg=0.63\n",
      "[629 | 358.05] loss=0.58 avg=0.63\n",
      "[630 | 358.52] loss=0.39 avg=0.63\n",
      "[631 | 359.00] loss=0.11 avg=0.63\n",
      "[632 | 359.47] loss=0.27 avg=0.62\n",
      "[633 | 359.94] loss=0.45 avg=0.62\n",
      "[634 | 360.41] loss=0.18 avg=0.62\n",
      "[635 | 360.88] loss=0.18 avg=0.61\n",
      "[636 | 361.36] loss=0.73 avg=0.61\n",
      "[637 | 361.83] loss=0.52 avg=0.61\n",
      "[638 | 362.30] loss=0.24 avg=0.61\n",
      "[639 | 362.77] loss=0.49 avg=0.61\n",
      "[640 | 363.24] loss=0.36 avg=0.60\n",
      "[641 | 363.71] loss=0.32 avg=0.60\n",
      "[642 | 364.18] loss=0.34 avg=0.60\n",
      "[643 | 364.66] loss=0.18 avg=0.59\n",
      "[644 | 365.13] loss=0.35 avg=0.59\n",
      "[645 | 365.60] loss=0.34 avg=0.59\n",
      "[646 | 366.07] loss=0.11 avg=0.59\n",
      "[647 | 366.54] loss=0.25 avg=0.58\n",
      "[648 | 367.01] loss=0.18 avg=0.58\n",
      "[649 | 367.48] loss=0.16 avg=0.57\n",
      "[650 | 367.95] loss=0.27 avg=0.57\n",
      "[651 | 368.42] loss=0.28 avg=0.57\n",
      "[652 | 368.89] loss=0.20 avg=0.56\n",
      "[653 | 369.37] loss=0.30 avg=0.56\n",
      "[654 | 369.84] loss=0.17 avg=0.56\n",
      "[655 | 370.31] loss=0.25 avg=0.55\n",
      "[656 | 370.78] loss=0.20 avg=0.55\n",
      "[657 | 371.25] loss=0.17 avg=0.55\n",
      "[658 | 371.73] loss=0.76 avg=0.55\n",
      "[659 | 372.20] loss=0.26 avg=0.55\n",
      "[660 | 372.67] loss=0.62 avg=0.55\n",
      "[661 | 373.14] loss=0.13 avg=0.54\n",
      "[662 | 373.62] loss=0.43 avg=0.54\n",
      "[663 | 374.09] loss=0.23 avg=0.54\n",
      "[664 | 374.56] loss=0.12 avg=0.53\n",
      "[665 | 375.04] loss=0.21 avg=0.53\n",
      "[666 | 375.51] loss=0.12 avg=0.53\n",
      "[667 | 375.98] loss=0.22 avg=0.52\n",
      "[668 | 376.45] loss=0.16 avg=0.52\n",
      "[669 | 376.92] loss=0.41 avg=0.52\n",
      "[670 | 377.40] loss=0.31 avg=0.52\n",
      "[671 | 377.87] loss=0.22 avg=0.51\n",
      "[672 | 378.35] loss=0.14 avg=0.51\n",
      "[673 | 378.82] loss=0.30 avg=0.51\n",
      "[674 | 379.29] loss=0.24 avg=0.51\n",
      "[675 | 379.76] loss=0.16 avg=0.50\n",
      "[676 | 380.23] loss=0.33 avg=0.50\n",
      "[677 | 380.71] loss=0.42 avg=0.50\n",
      "[678 | 381.18] loss=0.25 avg=0.50\n",
      "[679 | 381.66] loss=0.64 avg=0.50\n",
      "[680 | 382.13] loss=0.26 avg=0.50\n",
      "[681 | 382.60] loss=0.28 avg=0.49\n",
      "[682 | 383.07] loss=0.16 avg=0.49\n",
      "[683 | 383.55] loss=0.15 avg=0.49\n",
      "[684 | 384.02] loss=0.24 avg=0.48\n",
      "[685 | 384.49] loss=0.24 avg=0.48\n",
      "[686 | 384.97] loss=0.14 avg=0.48\n",
      "[687 | 385.44] loss=0.42 avg=0.48\n",
      "[688 | 385.92] loss=0.19 avg=0.47\n",
      "[689 | 386.39] loss=0.13 avg=0.47\n",
      "[690 | 386.86] loss=0.08 avg=0.47\n",
      "[691 | 387.34] loss=0.90 avg=0.47\n",
      "[692 | 387.81] loss=0.56 avg=0.47\n",
      "[693 | 388.28] loss=0.10 avg=0.47\n",
      "[694 | 388.75] loss=0.16 avg=0.47\n",
      "[695 | 389.23] loss=0.10 avg=0.46\n",
      "[696 | 389.70] loss=0.35 avg=0.46\n",
      "[697 | 390.17] loss=0.26 avg=0.46\n",
      "[698 | 390.65] loss=0.21 avg=0.46\n",
      "[699 | 391.12] loss=0.42 avg=0.46\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      "see, e.g., [34]). The diffusion tensor of the fibers, as we shall discuss in section 3,\n",
      "is a general-probing-interaction (GTPI) term that describes the distribution of fibers in the\n",
      "space of possible directions. The term also has a spatial limit of space = 100 n�m, that is\n",
      "the average of all the quantities (see [36]). The average of the quantities\n",
      "(in nanometers) is called the spatial gradient term [S] and it describes the movement\n",
      "of the fibers along the fibers' average direction. It is the directional\n",
      "input that determines the mean speed of the cells, whose average direction of motion\n",
      "affects the speed of light. Therefore, the average of the quantities\n",
      "S(x, y) = 1\n",
      "S(x, y)\n",
      "is called the spatial variance term (SUN) and it describes the\n",
      "local variability of the measured quantity S(x, y). It is the\n",
      "quantity concentration that determines the instantaneous variability of the measured\n",
      "quantity in the spatial volume (in µm) of the cell, that determines the macroscopic\n",
      "diffusion limit (see [35]). The term\n",
      "UNDATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATE |Uptimes out the average of the\n",
      "UNDATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATE |UTILATime`.\n",
      "(a) Fibers distribution. (b) Mainta monitor\n",
      "The average of the quantities (a, b) gives the macroscopic velocity (ucc)\n",
      "∂ Ωq = 0, meaning that the cells are moving in the direction ∂Ωq.\n",
      "∂Ω = 0, meaning that the cells are moving in the direction ∂Ωq. (c) Mainta monitor\n",
      "The average of the quantities (d, e) give the macroscopic velocity (ucc)\n",
      "∂ Ω = 0, meaning that the cells are moving in the direction ∂Ωq.\n",
      "(d − e) = 0, meaning that the cells are moving in the direction ∂Ωq.\n",
      "(e) t=1.25 (f) t=2.5\n",
      "(g) t=3.5 (h) t=4.5\n",
      "Figure 3: Test 3 Migration of cells in the direction centered at q and dotted circle. Right: center of radius = 0.25, while diagonalization is performed with -lS = 0.25.\n",
      "(a) t=1.875 (b) t=2.5 (c) t=3.5\n",
      "(d) t=5 (e) t=6.25\n",
      "Figure 4: Right: center of radius = 0.25, while diagonalization is performed with -lS = 0.25.\n",
      "(a) t=1.875 (b) t=2.5 (c) t=3.5 (d) t=5\n",
      "Figure 5: Right: center of radius = 0.25, while diagonalization is performed with -lS = 0.25.\n",
      "Figure 6: Test 3 Case i) with no external factors (b), internal chemotactic response (d−1), and\n",
      "cells migrate in the direction centered at (x, y). Details are shown inFig. 3a.\n",
      "Figure 7: Case ii) with no external factors (b), internal chemotactic response (d−1), and\n",
      "cells migrate in the direction centered at (x, y). Details are shown inFig. 3a.\n",
      "Figure 8: Case iii) with no external factors (b), internal chemotactic response (d−1), and\n",
      "cells migrate in the direction centered at (x, y). Details are shownFig. 3a.\n",
      "Figure 9: Case iv) with no external factors (b), internal chemotactic response (d−1), and\n",
      "cells migrate in the direction centered at (x, y). Details are shownFig. 3b.5\n",
      "Figure 10: Case v) with no external factors (b), internal chemotactic response (d−1), and\n",
      "cells migrate in the direction centered at (x, y). Details are shownFig. 3c.usk(x0, y0) + (z, v0) (y0, v1) = 0, thus motility\n",
      "0. The initial velocity is chemotaxis, as described previously for SEq. In the\n",
      "case of biased models, we consider only the chemoattractant S(x0, y0) and, in fact, the\n",
      "cells are slowed down and the cell cycle continues as before. In the presence\n",
      "of more chemotactic stimuli,\n",
      "\n",
      "[700 | 402.26] loss=0.39 avg=0.46\n",
      "[701 | 402.75] loss=0.30 avg=0.45\n",
      "[702 | 403.21] loss=0.17 avg=0.45\n",
      "[703 | 403.69] loss=0.07 avg=0.45\n",
      "[704 | 404.16] loss=0.09 avg=0.44\n",
      "[705 | 404.64] loss=0.22 avg=0.44\n",
      "[706 | 405.11] loss=0.24 avg=0.44\n",
      "[707 | 405.59] loss=0.28 avg=0.44\n",
      "[708 | 406.06] loss=0.25 avg=0.44\n",
      "[709 | 406.53] loss=0.22 avg=0.43\n",
      "[710 | 407.00] loss=0.19 avg=0.43\n",
      "[711 | 407.48] loss=0.21 avg=0.43\n",
      "[712 | 407.95] loss=0.11 avg=0.43\n",
      "[713 | 408.42] loss=0.19 avg=0.42\n",
      "[714 | 408.90] loss=0.20 avg=0.42\n",
      "[715 | 409.37] loss=0.16 avg=0.42\n",
      "[716 | 409.84] loss=0.17 avg=0.42\n",
      "[717 | 410.31] loss=0.21 avg=0.41\n",
      "[718 | 410.79] loss=0.27 avg=0.41\n",
      "[719 | 411.26] loss=0.20 avg=0.41\n",
      "[720 | 411.73] loss=0.15 avg=0.41\n",
      "[721 | 412.21] loss=0.20 avg=0.41\n",
      "[722 | 412.68] loss=0.10 avg=0.40\n",
      "[723 | 413.16] loss=0.15 avg=0.40\n",
      "[724 | 413.63] loss=0.39 avg=0.40\n",
      "[725 | 414.11] loss=0.40 avg=0.40\n",
      "[726 | 414.59] loss=0.15 avg=0.40\n",
      "[727 | 415.06] loss=0.28 avg=0.40\n",
      "[728 | 415.53] loss=0.24 avg=0.40\n",
      "[729 | 416.01] loss=0.18 avg=0.39\n",
      "[730 | 416.48] loss=0.23 avg=0.39\n",
      "[731 | 416.95] loss=0.28 avg=0.39\n",
      "[732 | 417.43] loss=0.17 avg=0.39\n",
      "[733 | 417.90] loss=0.38 avg=0.39\n",
      "[734 | 418.37] loss=0.18 avg=0.39\n",
      "[735 | 418.84] loss=0.23 avg=0.38\n",
      "[736 | 419.32] loss=0.21 avg=0.38\n",
      "[737 | 419.79] loss=0.19 avg=0.38\n",
      "[738 | 420.27] loss=0.28 avg=0.38\n",
      "[739 | 420.74] loss=0.17 avg=0.38\n",
      "[740 | 421.21] loss=0.28 avg=0.38\n",
      "[741 | 421.69] loss=0.12 avg=0.37\n",
      "[742 | 422.17] loss=0.43 avg=0.37\n",
      "[743 | 422.64] loss=0.32 avg=0.37\n",
      "[744 | 423.11] loss=0.19 avg=0.37\n",
      "[745 | 423.59] loss=0.20 avg=0.37\n",
      "[746 | 424.06] loss=0.12 avg=0.37\n",
      "[747 | 424.53] loss=0.10 avg=0.37\n",
      "[748 | 425.01] loss=0.07 avg=0.36\n",
      "[749 | 425.48] loss=0.15 avg=0.36\n",
      "[750 | 425.95] loss=0.18 avg=0.36\n",
      "[751 | 426.42] loss=0.11 avg=0.36\n",
      "[752 | 426.89] loss=0.34 avg=0.36\n",
      "[753 | 427.36] loss=0.25 avg=0.35\n",
      "[754 | 427.84] loss=0.16 avg=0.35\n",
      "[755 | 428.31] loss=0.54 avg=0.35\n",
      "[756 | 428.78] loss=0.23 avg=0.35\n",
      "[757 | 429.25] loss=0.26 avg=0.35\n",
      "[758 | 429.73] loss=0.42 avg=0.35\n",
      "[759 | 430.20] loss=0.15 avg=0.35\n",
      "[760 | 430.68] loss=0.20 avg=0.35\n",
      "[761 | 431.15] loss=0.18 avg=0.35\n",
      "[762 | 431.62] loss=0.14 avg=0.35\n",
      "[763 | 432.10] loss=0.61 avg=0.35\n",
      "[764 | 432.57] loss=0.09 avg=0.35\n",
      "[765 | 433.04] loss=0.15 avg=0.34\n",
      "[766 | 433.51] loss=0.34 avg=0.34\n",
      "[767 | 433.98] loss=0.27 avg=0.34\n",
      "[768 | 434.46] loss=0.17 avg=0.34\n",
      "[769 | 434.93] loss=0.25 avg=0.34\n",
      "[770 | 435.40] loss=0.14 avg=0.34\n",
      "[771 | 435.88] loss=0.63 avg=0.34\n",
      "[772 | 436.35] loss=0.13 avg=0.34\n",
      "[773 | 436.82] loss=0.35 avg=0.34\n",
      "[774 | 437.30] loss=0.21 avg=0.34\n",
      "[775 | 437.77] loss=0.14 avg=0.34\n",
      "[776 | 438.25] loss=0.15 avg=0.33\n",
      "[777 | 438.72] loss=0.11 avg=0.33\n",
      "[778 | 439.20] loss=0.08 avg=0.33\n",
      "[779 | 439.67] loss=0.14 avg=0.33\n",
      "[780 | 440.15] loss=0.41 avg=0.33\n",
      "[781 | 440.62] loss=0.16 avg=0.33\n",
      "[782 | 441.09] loss=0.32 avg=0.33\n",
      "[783 | 441.57] loss=0.10 avg=0.32\n",
      "[784 | 442.04] loss=0.18 avg=0.32\n",
      "[785 | 442.52] loss=0.14 avg=0.32\n",
      "[786 | 442.99] loss=0.20 avg=0.32\n",
      "[787 | 443.47] loss=0.25 avg=0.32\n",
      "[788 | 443.94] loss=0.17 avg=0.32\n",
      "[789 | 444.41] loss=0.12 avg=0.32\n",
      "[790 | 444.89] loss=0.20 avg=0.31\n",
      "[791 | 445.36] loss=0.13 avg=0.31\n",
      "[792 | 445.83] loss=0.58 avg=0.32\n",
      "[793 | 446.31] loss=0.17 avg=0.31\n",
      "[794 | 446.79] loss=0.13 avg=0.31\n",
      "[795 | 447.26] loss=0.20 avg=0.31\n",
      "[796 | 447.73] loss=0.18 avg=0.31\n",
      "[797 | 448.21] loss=0.17 avg=0.31\n",
      "[798 | 448.68] loss=0.45 avg=0.31\n",
      "[799 | 449.16] loss=0.13 avg=0.31\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      "o, a non-local sensing of the extracellular matrix. J. Math. Biol., 80:481–504, 2000.\n",
      "[14] J. M. Preziosi, A. A. Vecchio, M. D. Caldwell, and D. E. Burdaings. Modeling cell migration in an extracellular matrix. J. Math. Biol., 80:481–504, 2000.\n",
      "[15] T. Hillen. Semigroup generation properties of a topological progression operator over regular linear models\n",
      "derived from a non-local ECM model. Math. Biosci. Eng., 10:443–460, 2000.\n",
      "[16] T. Hillen, A. A. Vecchio, M. D. Caldwell, and D. E. Burdaings. Modelling cell migration in a non-polarized\n",
      "environment. J. Math. Biol., 80:481–504, 2000.\n",
      "[17] J. M. Preziosi, T. Hillen, and A. A. Vecchio. Directional dynamics of bacterial chemotaxis in a non-polarized\n",
      "environment. J. Math. Biol., 80:481–504, 2000.\n",
      "[18] T. Hillen and H. G. Othmer. Directional dynamics of bacterial chemotaxis in a non-polarized\n",
      "environment. J. Math. Biol., 80:481–504, 2000.\n",
      "[19] T. Hillen and H. G. Othmer. Adaptation of bacterial chemotaxis to a nutrient gradient. J. Math. Biol., 80:481–504, 2000.\n",
      "[20] T. Hillen, H. G. Othmer, and A. A. Vecchio. A non-local sensing of the extracellular matrix. Math. Mod. Meth. Appl. S.,\n",
      "53:1–107, 2000.\n",
      "[21] N. L. Hillen and L. E. Coombs. A non-local sensing of the extracellular matrix. J. Math. Biol.,\n",
      "53:1–116, 2002.\n",
      "[22] N. L. Hillen, L. E. Coombs, and A. A. M. Keely. A non-local sensing of the extracellular matrix. J. Math. Biol.,\n",
      "53:1–110, 2002.\n",
      "[23] N. L. Hillen and L. E. Coombs. A non-local sensing of the extracellular matrix in a non-polarized environment. Math. Mod. Meth. Appl. S.,\n",
      "53:1–116, 2005.\n",
      "[24] N. L. Hillen and L. E. Coombs. A non-local sensing of the extracellular matrix in a non-polarized environment. Math. Mod. Meth. Appl. S.,\n",
      "53:1–116, referring to (5).\n",
      "[25] N. L. Hillen and L. E. Coombs. A non-local sensing of the extracellular matrix in a non-polarized environment. Math. Mod.\n",
      "Sensing, L. Engle, L. Roncenzi, and A. A. Palce. Math. S., vol. 26, McGraw-Hill, Inc., pages 497–543, 1999.\n",
      "[26] N. L. Hillen and L. E. Coombs. A non-local, non-polarized, non-aligned, non-movement chemoattractant. Math. Mod. Meth. Appl. S., pages 177–222, 2005.\n",
      "[27] N. L. Hillen and L. E. Coombs. A non-local, non-aligned, non-aligned, and non-aligned sensing of the extracellular matrix. Math. Mod. Meth. Appl. S, pages 177–222, referring to (5).\n",
      "[28] N. L. Hillen and L. E. Coombs. A non-aligned, non-aligned, and non-aligned sensing of the extracellular matrix. Math. Mod. Meth. Appl. S, pages 177–222, referring to (5).\n",
      "[29] N. L. Hillen and L. E. Coombs. Modelling cell migration in a non-polarized environment. Math. Mod. Meth. Appl. S, pages 177–222, referring to (5).\n",
      "[30] N. L. Hillen and L. E. Coombs. Modelling cell migration in a non-aligned, non-aligned, and non-aligned substrate. Math. Mod. Meth. Appl. S, pages 177–222, referring to (5).\n",
      "[31] N. L. Hillen and L. E. Coombs. Modelling non\n",
      "\n",
      "[800 | 460.51] loss=0.34 avg=0.31\n",
      "[801 | 460.99] loss=0.12 avg=0.31\n",
      "[802 | 461.46] loss=0.15 avg=0.30\n",
      "[803 | 461.94] loss=0.11 avg=0.30\n",
      "[804 | 462.41] loss=0.10 avg=0.30\n",
      "[805 | 462.90] loss=0.17 avg=0.30\n",
      "[806 | 463.37] loss=0.32 avg=0.30\n",
      "[807 | 463.84] loss=0.14 avg=0.30\n",
      "[808 | 464.32] loss=0.23 avg=0.30\n",
      "[809 | 464.79] loss=0.13 avg=0.30\n",
      "[810 | 465.26] loss=0.16 avg=0.29\n",
      "[811 | 465.74] loss=0.25 avg=0.29\n",
      "[812 | 466.21] loss=0.17 avg=0.29\n",
      "[813 | 466.68] loss=0.27 avg=0.29\n",
      "[814 | 467.16] loss=0.25 avg=0.29\n",
      "[815 | 467.63] loss=0.23 avg=0.29\n",
      "[816 | 468.10] loss=0.14 avg=0.29\n",
      "[817 | 468.58] loss=0.17 avg=0.29\n",
      "[818 | 469.05] loss=0.17 avg=0.29\n",
      "[819 | 469.52] loss=0.19 avg=0.29\n",
      "[820 | 469.99] loss=0.11 avg=0.29\n",
      "[821 | 470.47] loss=0.15 avg=0.28\n",
      "[822 | 470.94] loss=0.15 avg=0.28\n",
      "[823 | 471.41] loss=0.21 avg=0.28\n",
      "[824 | 471.89] loss=0.13 avg=0.28\n",
      "[825 | 472.36] loss=0.11 avg=0.28\n",
      "[826 | 472.83] loss=0.29 avg=0.28\n",
      "[827 | 473.31] loss=0.27 avg=0.28\n",
      "[828 | 473.78] loss=0.29 avg=0.28\n",
      "[829 | 474.26] loss=1.17 avg=0.29\n",
      "[830 | 474.73] loss=0.17 avg=0.29\n",
      "[831 | 475.21] loss=0.12 avg=0.28\n",
      "[832 | 475.68] loss=0.07 avg=0.28\n",
      "[833 | 476.15] loss=0.17 avg=0.28\n",
      "[834 | 476.62] loss=0.31 avg=0.28\n",
      "[835 | 477.10] loss=0.14 avg=0.28\n",
      "[836 | 477.57] loss=0.33 avg=0.28\n",
      "[837 | 478.04] loss=0.15 avg=0.28\n",
      "[838 | 478.52] loss=0.32 avg=0.28\n",
      "[839 | 478.99] loss=0.14 avg=0.28\n",
      "[840 | 479.47] loss=0.16 avg=0.28\n",
      "[841 | 479.94] loss=0.15 avg=0.28\n",
      "[842 | 480.41] loss=0.28 avg=0.28\n",
      "[843 | 480.88] loss=0.13 avg=0.27\n",
      "[844 | 481.36] loss=0.35 avg=0.28\n",
      "[845 | 481.83] loss=0.08 avg=0.27\n",
      "[846 | 482.30] loss=0.10 avg=0.27\n",
      "[847 | 482.78] loss=0.12 avg=0.27\n",
      "[848 | 483.25] loss=0.15 avg=0.27\n",
      "[849 | 483.73] loss=0.10 avg=0.27\n",
      "[850 | 484.21] loss=0.14 avg=0.27\n",
      "[851 | 484.68] loss=0.82 avg=0.27\n",
      "[852 | 485.15] loss=0.08 avg=0.27\n",
      "[853 | 485.63] loss=0.24 avg=0.27\n",
      "[854 | 486.10] loss=0.38 avg=0.27\n",
      "[855 | 486.57] loss=0.16 avg=0.27\n",
      "[856 | 487.05] loss=0.19 avg=0.27\n",
      "[857 | 487.52] loss=0.20 avg=0.27\n",
      "[858 | 487.99] loss=0.19 avg=0.27\n",
      "[859 | 488.47] loss=0.12 avg=0.27\n",
      "[860 | 488.94] loss=0.19 avg=0.27\n",
      "[861 | 489.42] loss=0.17 avg=0.26\n",
      "[862 | 489.89] loss=0.15 avg=0.26\n",
      "[863 | 490.37] loss=0.18 avg=0.26\n",
      "[864 | 490.84] loss=0.12 avg=0.26\n",
      "[865 | 491.31] loss=0.11 avg=0.26\n",
      "[866 | 491.79] loss=0.19 avg=0.26\n",
      "[867 | 492.27] loss=0.17 avg=0.26\n",
      "[868 | 492.74] loss=0.18 avg=0.26\n",
      "[869 | 493.22] loss=0.26 avg=0.26\n",
      "[870 | 493.69] loss=0.09 avg=0.26\n",
      "[871 | 494.17] loss=0.13 avg=0.25\n",
      "[872 | 494.64] loss=0.14 avg=0.25\n",
      "[873 | 495.11] loss=0.57 avg=0.26\n",
      "[874 | 495.59] loss=0.12 avg=0.25\n",
      "[875 | 496.06] loss=0.13 avg=0.25\n",
      "[876 | 496.53] loss=0.15 avg=0.25\n",
      "[877 | 497.00] loss=0.12 avg=0.25\n",
      "[878 | 497.47] loss=0.15 avg=0.25\n",
      "[879 | 497.95] loss=0.18 avg=0.25\n",
      "[880 | 498.42] loss=0.09 avg=0.25\n",
      "[881 | 498.89] loss=0.14 avg=0.25\n",
      "[882 | 499.36] loss=0.12 avg=0.25\n",
      "[883 | 499.84] loss=0.15 avg=0.24\n",
      "[884 | 500.31] loss=0.39 avg=0.25\n",
      "[885 | 500.78] loss=0.10 avg=0.24\n",
      "[886 | 501.25] loss=0.27 avg=0.24\n",
      "[887 | 501.73] loss=0.09 avg=0.24\n",
      "[888 | 502.20] loss=0.13 avg=0.24\n",
      "[889 | 502.68] loss=0.11 avg=0.24\n",
      "[890 | 503.15] loss=0.12 avg=0.24\n",
      "[891 | 503.62] loss=0.07 avg=0.24\n",
      "[892 | 504.09] loss=0.09 avg=0.24\n",
      "[893 | 504.57] loss=0.13 avg=0.24\n",
      "[894 | 505.04] loss=0.30 avg=0.24\n",
      "[895 | 505.51] loss=0.09 avg=0.23\n",
      "[896 | 505.99] loss=0.28 avg=0.23\n",
      "[897 | 506.46] loss=0.14 avg=0.23\n",
      "[898 | 506.93] loss=0.15 avg=0.23\n",
      "[899 | 507.40] loss=0.11 avg=0.23\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " (1)\n",
      "and (2)\n",
      "given the fibers distribution, we choose\n",
      "fibers =\n",
      "1\n",
      "Γ\n",
      "q\n",
      "(ξ, v, vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ\n",
      "13\n",
      "and\n",
      "Γ\n",
      "q\n",
      "(ξ, v, vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ ,\n",
      "with\n",
      "c0\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ .\n",
      "Let us now define\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ = Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ , (47)\n",
      "and, then, we have\n",
      "c0\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ , (48)\n",
      "and\n",
      "c1\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ , (49)\n",
      "and\n",
      "c2\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c1\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and finally\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d−1\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ + c2\n",
      "and, finally, we have\n",
      "Γ\n",
      "q\n",
      ":= Z\n",
      "S\n",
      "d\n",
      "\n",
      "[900 | 518.50] loss=0.17 avg=0.23\n",
      "[901 | 518.99] loss=0.11 avg=0.23\n",
      "[902 | 519.45] loss=0.16 avg=0.23\n",
      "[903 | 519.93] loss=0.10 avg=0.23\n",
      "[904 | 520.40] loss=0.29 avg=0.23\n",
      "[905 | 520.86] loss=0.11 avg=0.23\n",
      "[906 | 521.33] loss=0.22 avg=0.23\n",
      "[907 | 521.81] loss=0.13 avg=0.23\n",
      "[908 | 522.29] loss=0.12 avg=0.23\n",
      "[909 | 522.75] loss=0.20 avg=0.23\n",
      "[910 | 523.23] loss=0.10 avg=0.22\n",
      "[911 | 523.70] loss=0.14 avg=0.22\n",
      "[912 | 524.17] loss=0.12 avg=0.22\n",
      "[913 | 524.64] loss=0.32 avg=0.22\n",
      "[914 | 525.11] loss=0.07 avg=0.22\n",
      "[915 | 525.58] loss=0.12 avg=0.22\n",
      "[916 | 526.05] loss=0.11 avg=0.22\n",
      "[917 | 526.52] loss=0.14 avg=0.22\n",
      "[918 | 526.99] loss=0.06 avg=0.22\n",
      "[919 | 527.46] loss=0.06 avg=0.22\n",
      "[920 | 527.93] loss=0.13 avg=0.21\n",
      "[921 | 528.41] loss=0.35 avg=0.22\n",
      "[922 | 528.88] loss=0.09 avg=0.21\n",
      "[923 | 529.35] loss=0.20 avg=0.21\n",
      "[924 | 529.82] loss=0.07 avg=0.21\n",
      "[925 | 530.30] loss=0.08 avg=0.21\n",
      "[926 | 530.77] loss=0.34 avg=0.21\n",
      "[927 | 531.24] loss=0.21 avg=0.21\n",
      "[928 | 531.72] loss=0.08 avg=0.21\n",
      "[929 | 532.19] loss=0.08 avg=0.21\n",
      "[930 | 532.66] loss=0.14 avg=0.21\n",
      "[931 | 533.13] loss=0.07 avg=0.21\n",
      "[932 | 533.61] loss=0.13 avg=0.21\n",
      "[933 | 534.08] loss=0.13 avg=0.21\n",
      "[934 | 534.55] loss=0.06 avg=0.21\n",
      "[935 | 535.03] loss=0.17 avg=0.20\n",
      "[936 | 535.50] loss=0.06 avg=0.20\n",
      "[937 | 535.97] loss=0.30 avg=0.20\n",
      "[938 | 536.44] loss=0.26 avg=0.20\n",
      "[939 | 536.92] loss=0.18 avg=0.20\n",
      "[940 | 537.39] loss=0.19 avg=0.20\n",
      "[941 | 537.86] loss=0.15 avg=0.20\n",
      "[942 | 538.34] loss=0.10 avg=0.20\n",
      "[943 | 538.81] loss=0.15 avg=0.20\n",
      "[944 | 539.28] loss=0.13 avg=0.20\n",
      "[945 | 539.75] loss=0.09 avg=0.20\n",
      "[946 | 540.22] loss=0.11 avg=0.20\n",
      "[947 | 540.70] loss=0.13 avg=0.20\n",
      "[948 | 541.17] loss=0.07 avg=0.20\n",
      "[949 | 541.64] loss=0.12 avg=0.20\n",
      "[950 | 542.11] loss=0.09 avg=0.20\n",
      "[951 | 542.58] loss=0.10 avg=0.19\n",
      "[952 | 543.05] loss=0.13 avg=0.19\n",
      "[953 | 543.53] loss=0.09 avg=0.19\n",
      "[954 | 544.00] loss=0.11 avg=0.19\n",
      "[955 | 544.47] loss=0.15 avg=0.19\n",
      "[956 | 544.95] loss=0.12 avg=0.19\n",
      "[957 | 545.42] loss=0.10 avg=0.19\n",
      "[958 | 545.89] loss=0.08 avg=0.19\n",
      "[959 | 546.36] loss=0.08 avg=0.19\n",
      "[960 | 546.84] loss=0.09 avg=0.19\n",
      "[961 | 547.31] loss=0.14 avg=0.19\n",
      "[962 | 547.79] loss=0.12 avg=0.19\n",
      "[963 | 548.26] loss=0.23 avg=0.19\n",
      "[964 | 548.73] loss=0.11 avg=0.19\n",
      "[965 | 549.20] loss=0.06 avg=0.18\n",
      "[966 | 549.68] loss=0.10 avg=0.18\n",
      "[967 | 550.15] loss=0.23 avg=0.18\n",
      "[968 | 550.63] loss=0.17 avg=0.18\n",
      "[969 | 551.10] loss=0.12 avg=0.18\n",
      "[970 | 551.58] loss=0.10 avg=0.18\n",
      "[971 | 552.05] loss=0.19 avg=0.18\n",
      "[972 | 552.53] loss=0.10 avg=0.18\n",
      "[973 | 553.00] loss=0.08 avg=0.18\n",
      "[974 | 553.47] loss=0.10 avg=0.18\n",
      "[975 | 553.95] loss=0.13 avg=0.18\n",
      "[976 | 554.42] loss=0.08 avg=0.18\n",
      "[977 | 554.89] loss=0.20 avg=0.18\n",
      "[978 | 555.37] loss=0.10 avg=0.18\n",
      "[979 | 555.84] loss=0.09 avg=0.18\n",
      "[980 | 556.32] loss=0.14 avg=0.18\n",
      "[981 | 556.79] loss=0.12 avg=0.18\n",
      "[982 | 557.27] loss=0.12 avg=0.18\n",
      "[983 | 557.74] loss=0.10 avg=0.17\n",
      "[984 | 558.22] loss=0.13 avg=0.17\n",
      "[985 | 558.69] loss=0.09 avg=0.17\n",
      "[986 | 559.17] loss=0.10 avg=0.17\n",
      "[987 | 559.64] loss=0.09 avg=0.17\n",
      "[988 | 560.12] loss=0.12 avg=0.17\n",
      "[989 | 560.59] loss=0.10 avg=0.17\n",
      "[990 | 561.07] loss=0.12 avg=0.17\n",
      "[991 | 561.54] loss=0.08 avg=0.17\n",
      "[992 | 562.01] loss=0.10 avg=0.17\n",
      "[993 | 562.48] loss=0.09 avg=0.17\n",
      "[994 | 562.96] loss=0.09 avg=0.17\n",
      "[995 | 563.43] loss=0.08 avg=0.17\n",
      "[996 | 563.90] loss=0.09 avg=0.17\n",
      "[997 | 564.38] loss=0.11 avg=0.16\n",
      "[998 | 564.85] loss=0.12 avg=0.16\n",
      "[999 | 565.33] loss=0.08 avg=0.16\n",
      "Saving checkpoint/run1/model-1000\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      "��\n",
      "γq(λ)S(x + λvˆ) dλi\n",
      "ψ(v)\n",
      "(54)\n",
      "where\n",
      "c0(x)\n",
      "−1\n",
      ":= 2 Z\n",
      "S\n",
      "d−1\n",
      "q(x, vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "U¯ Γ\n",
      "q\n",
      "1\n",
      "c1(x)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ\n",
      "(55)\n",
      "and\n",
      "c1(vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ (56)\n",
      "both of which are given by the measure of the chemoattractant S(x + λvˆ) in vˆ. Furthermore, the non-local independent sensing is given by the\n",
      "incapacitation time\n",
      "T[q, S](x, v, vˆ) = c(x)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "U¯ Γ\n",
      "S\n",
      "1\n",
      "S\n",
      "(x)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ\n",
      "(57)\n",
      "and\n",
      "U¯ Γ\n",
      "S\n",
      "1\n",
      "(v)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ (58)\n",
      "both of which are given by the measure of the absorber\n",
      "U¯ Γ\n",
      "S\n",
      "1\n",
      "S\n",
      "(x)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ (59)\n",
      "both of which are given by the average of the spatial variability of the external sensing center\n",
      "T0[q, S](ξ, v, vˆ) = 1\n",
      "Γ\n",
      "q\n",
      "0\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "vˆ ⊗ vˆ ∇q\n",
      "Z\n",
      "R+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ\n",
      "+\n",
      "U¯ Γ\n",
      "q\n",
      "1\n",
      "Γ\n",
      "q\n",
      "1\n",
      "Γ\n",
      "S\n",
      "1\n",
      "(vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ , (60)\n",
      "and the non-local independent sensing model is also given by (24). The mean direction of the fibers is given by the measure of the mean square of the fiber size\n",
      "Z\n",
      "R+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ = 0.02, (61)\n",
      "and the diffusion tensor of the fibers is given by (24). The chemoattractant has a hyperbolic limit\n",
      "D\n",
      "0\n",
      "T\n",
      "(ξ) = Z\n",
      "S\n",
      "d−1\n",
      "vˆ ⊗ vˆ q(ξ, vˆ) dvˆ dvˆ\n",
      "(62)\n",
      "and\n",
      "the diffusion-advection equation (23). The first condition, being the diffusion tensor of the fibers, is the velocity\n",
      "D\n",
      "0\n",
      "T\n",
      "(ξ) = Z\n",
      "S\n",
      "d−1\n",
      "vˆ ⊗ vˆ ∇q(ξ, vˆ) dvˆ dvˆ , (63)\n",
      "and the second condition being the non-local independent sensing of the fibers of the first order. This is related to the\n",
      "dropping time, that is that of the classical sliding average of the two quantities, is the same as the\n",
      "dropping time of the chemoattractant, because it only depends on the second-order\n",
      "diffusion field, but also depends on the first-order cues. Therefore, the sensing time of the cells will be\n",
      "D\n",
      "0\n",
      "T\n",
      "(ξ) = Z\n",
      "S\n",
      "d−1\n",
      "vˆ ⊗ vˆ q(ξ, vˆ) dvˆ dvˆ , (64)\n",
      "and the diffusion-advection equation (22).\n",
      "2.2 Boundary conditions\n",
      "Since we are going to consider two-dimensional bounded domains without loss of cells and no chemotaxis, we\n",
      "shall assume that the fibers density is proportional to the characteristic length\n",
      "D\n",
      "0\n",
      "T\n",
      "(ξ) = Z\n",
      "S\n",
      "d−\n",
      "\n",
      "[1000 | 578.99] loss=0.09 avg=0.16\n",
      "[1001 | 579.47] loss=0.18 avg=0.16\n",
      "[1002 | 579.93] loss=0.20 avg=0.16\n",
      "[1003 | 580.41] loss=0.19 avg=0.16\n",
      "[1004 | 580.87] loss=0.06 avg=0.16\n",
      "[1005 | 581.34] loss=0.10 avg=0.16\n",
      "[1006 | 581.82] loss=0.08 avg=0.16\n",
      "[1007 | 582.29] loss=0.07 avg=0.16\n",
      "[1008 | 582.76] loss=0.08 avg=0.16\n",
      "[1009 | 583.23] loss=0.12 avg=0.16\n",
      "[1010 | 583.69] loss=0.23 avg=0.16\n",
      "[1011 | 584.17] loss=0.08 avg=0.16\n",
      "[1012 | 584.64] loss=0.08 avg=0.16\n",
      "[1013 | 585.11] loss=0.07 avg=0.16\n",
      "[1014 | 585.58] loss=0.06 avg=0.16\n",
      "[1015 | 586.05] loss=0.07 avg=0.16\n",
      "[1016 | 586.52] loss=0.07 avg=0.15\n",
      "[1017 | 586.99] loss=0.06 avg=0.15\n",
      "[1018 | 587.46] loss=0.10 avg=0.15\n",
      "[1019 | 587.94] loss=0.10 avg=0.15\n",
      "[1020 | 588.40] loss=0.08 avg=0.15\n",
      "[1021 | 588.87] loss=0.06 avg=0.15\n",
      "[1022 | 589.34] loss=0.09 avg=0.15\n",
      "[1023 | 589.80] loss=0.07 avg=0.15\n",
      "[1024 | 590.27] loss=0.17 avg=0.15\n",
      "[1025 | 590.74] loss=0.16 avg=0.15\n",
      "[1026 | 591.21] loss=0.10 avg=0.15\n",
      "[1027 | 591.67] loss=0.18 avg=0.15\n",
      "[1028 | 592.14] loss=0.08 avg=0.15\n",
      "[1029 | 592.62] loss=0.13 avg=0.15\n",
      "[1030 | 593.09] loss=0.14 avg=0.15\n",
      "[1031 | 593.56] loss=0.14 avg=0.15\n",
      "[1032 | 594.03] loss=0.26 avg=0.15\n",
      "[1033 | 594.50] loss=0.07 avg=0.15\n",
      "[1034 | 594.97] loss=0.13 avg=0.15\n",
      "[1035 | 595.44] loss=0.06 avg=0.15\n",
      "[1036 | 595.91] loss=0.06 avg=0.15\n",
      "[1037 | 596.38] loss=0.08 avg=0.15\n",
      "[1038 | 596.85] loss=0.15 avg=0.15\n",
      "[1039 | 597.32] loss=0.10 avg=0.15\n",
      "[1040 | 597.80] loss=0.08 avg=0.14\n",
      "[1041 | 598.27] loss=0.13 avg=0.14\n",
      "[1042 | 598.74] loss=0.15 avg=0.14\n",
      "[1043 | 599.20] loss=0.06 avg=0.14\n",
      "[1044 | 599.67] loss=0.10 avg=0.14\n",
      "[1045 | 600.14] loss=0.11 avg=0.14\n",
      "[1046 | 600.61] loss=0.05 avg=0.14\n",
      "[1047 | 601.08] loss=0.06 avg=0.14\n",
      "[1048 | 601.56] loss=0.10 avg=0.14\n",
      "[1049 | 602.03] loss=0.15 avg=0.14\n",
      "[1050 | 602.50] loss=0.15 avg=0.14\n",
      "[1051 | 602.97] loss=0.09 avg=0.14\n",
      "[1052 | 603.44] loss=0.18 avg=0.14\n",
      "[1053 | 603.91] loss=0.08 avg=0.14\n",
      "[1054 | 604.38] loss=0.14 avg=0.14\n",
      "[1055 | 604.85] loss=0.10 avg=0.14\n",
      "[1056 | 605.32] loss=0.11 avg=0.14\n",
      "[1057 | 605.79] loss=0.08 avg=0.14\n",
      "[1058 | 606.26] loss=0.10 avg=0.14\n",
      "[1059 | 606.73] loss=0.08 avg=0.14\n",
      "[1060 | 607.21] loss=0.09 avg=0.14\n",
      "[1061 | 607.67] loss=0.05 avg=0.14\n",
      "[1062 | 608.14] loss=0.12 avg=0.14\n",
      "[1063 | 608.61] loss=0.08 avg=0.14\n",
      "[1064 | 609.08] loss=0.11 avg=0.14\n",
      "[1065 | 609.55] loss=0.06 avg=0.13\n",
      "[1066 | 610.01] loss=0.20 avg=0.14\n",
      "[1067 | 610.48] loss=0.20 avg=0.14\n",
      "[1068 | 610.95] loss=0.06 avg=0.14\n",
      "[1069 | 611.42] loss=0.11 avg=0.14\n",
      "[1070 | 611.89] loss=0.08 avg=0.13\n",
      "[1071 | 612.36] loss=0.08 avg=0.13\n",
      "[1072 | 612.83] loss=0.17 avg=0.13\n",
      "[1073 | 613.30] loss=0.08 avg=0.13\n",
      "[1074 | 613.77] loss=0.08 avg=0.13\n",
      "[1075 | 614.24] loss=0.10 avg=0.13\n",
      "[1076 | 614.72] loss=0.24 avg=0.13\n",
      "[1077 | 615.19] loss=0.12 avg=0.13\n",
      "[1078 | 615.66] loss=0.16 avg=0.13\n",
      "[1079 | 616.13] loss=0.12 avg=0.13\n",
      "[1080 | 616.60] loss=0.14 avg=0.13\n",
      "[1081 | 617.07] loss=0.14 avg=0.13\n",
      "[1082 | 617.54] loss=0.11 avg=0.13\n",
      "[1083 | 618.01] loss=0.07 avg=0.13\n",
      "[1084 | 618.48] loss=0.14 avg=0.13\n",
      "[1085 | 618.95] loss=0.11 avg=0.13\n",
      "[1086 | 619.42] loss=0.07 avg=0.13\n",
      "[1087 | 619.89] loss=0.31 avg=0.13\n",
      "[1088 | 620.37] loss=0.06 avg=0.13\n",
      "[1089 | 620.84] loss=0.06 avg=0.13\n",
      "[1090 | 621.30] loss=0.11 avg=0.13\n",
      "[1091 | 621.77] loss=0.07 avg=0.13\n",
      "[1092 | 622.24] loss=0.16 avg=0.13\n",
      "[1093 | 622.71] loss=0.13 avg=0.13\n",
      "[1094 | 623.18] loss=0.05 avg=0.13\n",
      "[1095 | 623.65] loss=0.15 avg=0.13\n",
      "[1096 | 624.12] loss=0.08 avg=0.13\n",
      "[1097 | 624.60] loss=0.13 avg=0.13\n",
      "[1098 | 625.07] loss=0.03 avg=0.13\n",
      "[1099 | 625.54] loss=0.07 avg=0.13\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " imposed, in the first instance, a measure of the spatial variability of the external guidance cues, whilst in the second instance,\n",
      "the spatial variability of the external cues is measured. In particular, we analyzed two possible scenarios: in the first\n",
      "instance, we can compare the two scenarios and in the second scenario, we can consider the macroscopic limits of the transport model.\n",
      "Case i) In this case, we can extend the transport model with a different parameterization and, thus, a different\n",
      "additivity term, namely diffusion tensor of the fibers distribution. Therefore, we can perform a microscopic microscopic limit on the fiber\n",
      "density of the fibers and a macroscopic weight on the fibers density.\n",
      "Case ii) In this case, we can extend the transport model with a different parameterization and, thus, a different\n",
      "additivity term, namely diffusion tensor of the fibers distribution. In this case, we may choose to apply a diffusive or a advective\n",
      "weighting of the fibers on the fibers' velocity and on the speeds they can go without affecting the\n",
      "density of the fibers themselves. As first scenario, we shall consider the transport model with a diffusive limit and a\n",
      "competitive weighted diffusion operator. In this case, we can expand both of the parameters and, starting from the lowest,\n",
      "we obtain a macroscopic bounding-storage equation for the fibers and a competitive\n",
      "agent. Setting the parameter i from i that I consider the most important, I then\n",
      "weight the two operators according to the following parameters:\n",
      "a) weighted by the overall mean velocity of the fibers in every direction, multiplied by the\n",
      "second sensitivity of the eye, and set to the weighted most appropriate value.\n",
      "b) weighted by the overall mean direction of the fibers in every direction, multiplied by the second\n",
      "sensing sensitivity, and set to the weighted most appropriate value. c) weighted by the direction of the fibers in every direction\n",
      "(see Fig. 3a).\n",
      "23\n",
      "Since we are considering a cellular analogy, we shall consider a cell in state i) and (2, 2), and (4, 4) are independent\n",
      "cells, respectively. Therefore, we shall consider a second guidance cue, one that mimics the cell's\n",
      "tumor response, and a third one that mimics the response of the central nervous system to the\n",
      "direction of the fibers.\n",
      "2.2 Adaptation model for cell migration on local sensing cells\n",
      "As first scenario, we shall consider a cellular population that is able to efficiently navigate\n",
      "the multi-directional, shifting environment of a heterogenous fibrous matrix. In particular, we\n",
      "shall consider moving the photoreceptor, which is located in the region of highly aligned fibers,\n",
      "between the preferential fixation point for chemotaxis and the preferential region of strongly aligned fibers. In\n",
      "case iii), we consider a second photoreceptor capable of distinguishing between the two cues, capable of\n",
      "referring between two different targets and generating and out of zero reaching out to\n",
      "reach the chemoattractant. In case iv), we consider a non-local independent sensing model with a\n",
      "preferential cue for chemotaxis. In particular, we shall consider a non-local, non-sensing cell with\n",
      "the characteristic phenotypic feature of the migration adapted photoreceptor. In particular,\n",
      "I, ii) γS , iii) = 1, γq(λ − λ), (75) and (26).\n",
      "4.4 Test 3: non-local independent sensing model\n",
      "As a first example, i) in each of the two settings, we can observe that the\n",
      "phenomena identified in Fig. 3c-e are not the result of a material cue, but rather a\n",
      "different, more specific cue. For instance, if, for example,kuso et al. [43] observe that of cells that\n",
      "are closely aligned in Fig. 3c-e, 53% of the time, they are migrating in a non-aligned\n",
      "direction, while in Fig. 3f, 54. The distribution of fibers in Fig. 3g-53 appears more\n",
      "dominant in Fig. 3h, while in Fig. 3i, ii) and iii) are more dominated by the\n",
      "phenomena identified in Fig. 3i, which are more dominated by the migration adapted photoreceptor?\n",
      "In particular, in Fig. 3j-iii) there are clear directional gradations, while in Fig. 3k) and in Fig. 3l) the\n",
      "phenomena identified in Fig. 3m are more evident in Fig. 3n. This suggests that\n",
      "the fibers are being directed by a different factor than k(x, y), that might be related to\n",
      "the preferential orientation of the haptoglobin transport kernel in the extracellular matrix. In\n",
      "fact, as studied in a few examples in the last two and a half years, the same phenomenon can occur with\n",
      "\n",
      "\n",
      "[1100 | 636.59] loss=0.10 avg=0.13\n",
      "[1101 | 637.08] loss=0.07 avg=0.13\n",
      "[1102 | 637.54] loss=0.16 avg=0.13\n",
      "[1103 | 638.02] loss=0.10 avg=0.13\n",
      "[1104 | 638.49] loss=0.20 avg=0.13\n",
      "[1105 | 638.96] loss=0.19 avg=0.13\n",
      "[1106 | 639.43] loss=0.11 avg=0.13\n",
      "[1107 | 639.91] loss=0.11 avg=0.13\n",
      "[1108 | 640.38] loss=0.08 avg=0.13\n",
      "[1109 | 640.84] loss=0.10 avg=0.13\n",
      "[1110 | 641.31] loss=0.06 avg=0.13\n",
      "[1111 | 641.78] loss=0.05 avg=0.13\n",
      "[1112 | 642.25] loss=0.08 avg=0.13\n",
      "[1113 | 642.72] loss=0.06 avg=0.13\n",
      "[1114 | 643.19] loss=0.05 avg=0.13\n",
      "[1115 | 643.66] loss=0.09 avg=0.13\n",
      "[1116 | 644.13] loss=0.05 avg=0.12\n",
      "[1117 | 644.60] loss=0.11 avg=0.12\n",
      "[1118 | 645.07] loss=0.10 avg=0.12\n",
      "[1119 | 645.55] loss=0.05 avg=0.12\n",
      "[1120 | 646.02] loss=0.19 avg=0.12\n",
      "[1121 | 646.49] loss=0.07 avg=0.12\n",
      "[1122 | 646.96] loss=0.09 avg=0.12\n",
      "[1123 | 647.43] loss=0.07 avg=0.12\n",
      "[1124 | 647.90] loss=0.07 avg=0.12\n",
      "[1125 | 648.37] loss=0.08 avg=0.12\n",
      "[1126 | 648.85] loss=0.08 avg=0.12\n",
      "[1127 | 649.31] loss=0.11 avg=0.12\n",
      "[1128 | 649.78] loss=0.14 avg=0.12\n",
      "[1129 | 650.25] loss=0.50 avg=0.12\n",
      "[1130 | 650.72] loss=0.08 avg=0.12\n",
      "[1131 | 651.19] loss=0.14 avg=0.12\n",
      "[1132 | 651.66] loss=0.06 avg=0.12\n",
      "[1133 | 652.14] loss=0.06 avg=0.12\n",
      "[1134 | 652.60] loss=0.12 avg=0.12\n",
      "[1135 | 653.07] loss=0.08 avg=0.12\n",
      "[1136 | 653.54] loss=0.04 avg=0.12\n",
      "[1137 | 654.01] loss=0.09 avg=0.12\n",
      "[1138 | 654.49] loss=0.07 avg=0.12\n",
      "[1139 | 654.96] loss=0.05 avg=0.12\n",
      "[1140 | 655.43] loss=0.12 avg=0.12\n",
      "[1141 | 655.90] loss=0.08 avg=0.12\n",
      "[1142 | 656.37] loss=0.21 avg=0.12\n",
      "[1143 | 656.85] loss=0.04 avg=0.12\n",
      "[1144 | 657.32] loss=0.09 avg=0.12\n",
      "[1145 | 657.79] loss=0.12 avg=0.12\n",
      "[1146 | 658.25] loss=0.08 avg=0.12\n",
      "[1147 | 658.72] loss=0.09 avg=0.12\n",
      "[1148 | 659.20] loss=0.14 avg=0.12\n",
      "[1149 | 659.67] loss=0.15 avg=0.12\n",
      "[1150 | 660.14] loss=0.11 avg=0.12\n",
      "[1151 | 660.61] loss=0.07 avg=0.12\n",
      "[1152 | 661.08] loss=0.06 avg=0.12\n",
      "[1153 | 661.55] loss=0.07 avg=0.12\n",
      "[1154 | 662.02] loss=0.06 avg=0.12\n",
      "[1155 | 662.49] loss=0.07 avg=0.12\n",
      "[1156 | 662.96] loss=0.09 avg=0.12\n",
      "[1157 | 663.43] loss=0.10 avg=0.12\n",
      "[1158 | 663.90] loss=0.10 avg=0.12\n",
      "[1159 | 664.38] loss=0.05 avg=0.12\n",
      "[1160 | 664.85] loss=0.08 avg=0.12\n",
      "[1161 | 665.32] loss=0.26 avg=0.12\n",
      "[1162 | 665.79] loss=0.15 avg=0.12\n",
      "[1163 | 666.26] loss=0.08 avg=0.12\n",
      "[1164 | 666.73] loss=0.07 avg=0.12\n",
      "[1165 | 667.21] loss=0.07 avg=0.12\n",
      "[1166 | 667.68] loss=0.06 avg=0.12\n",
      "[1167 | 668.15] loss=0.18 avg=0.12\n",
      "[1168 | 668.62] loss=0.09 avg=0.12\n",
      "[1169 | 669.08] loss=0.08 avg=0.12\n",
      "[1170 | 669.55] loss=0.09 avg=0.12\n",
      "[1171 | 670.02] loss=0.08 avg=0.11\n",
      "[1172 | 670.49] loss=0.06 avg=0.11\n",
      "[1173 | 670.97] loss=0.11 avg=0.11\n",
      "[1174 | 671.44] loss=0.09 avg=0.11\n",
      "[1175 | 671.91] loss=0.09 avg=0.11\n",
      "[1176 | 672.38] loss=0.11 avg=0.11\n",
      "[1177 | 672.85] loss=0.21 avg=0.11\n",
      "[1178 | 673.32] loss=0.06 avg=0.11\n",
      "[1179 | 673.79] loss=0.04 avg=0.11\n",
      "[1180 | 674.27] loss=0.09 avg=0.11\n",
      "[1181 | 674.74] loss=0.09 avg=0.11\n",
      "[1182 | 675.21] loss=0.10 avg=0.11\n",
      "[1183 | 675.68] loss=0.11 avg=0.11\n",
      "[1184 | 676.15] loss=0.09 avg=0.11\n",
      "[1185 | 676.62] loss=0.08 avg=0.11\n",
      "[1186 | 677.10] loss=0.06 avg=0.11\n",
      "[1187 | 677.57] loss=0.07 avg=0.11\n",
      "[1188 | 678.04] loss=0.10 avg=0.11\n",
      "[1189 | 678.51] loss=0.07 avg=0.11\n",
      "[1190 | 678.98] loss=0.03 avg=0.11\n",
      "[1191 | 679.45] loss=0.07 avg=0.11\n",
      "[1192 | 679.92] loss=0.50 avg=0.11\n",
      "[1193 | 680.40] loss=0.09 avg=0.11\n",
      "[1194 | 680.87] loss=0.10 avg=0.11\n",
      "[1195 | 681.34] loss=0.08 avg=0.11\n",
      "[1196 | 681.81] loss=0.07 avg=0.11\n",
      "[1197 | 682.28] loss=0.07 avg=0.11\n",
      "[1198 | 682.75] loss=0.08 avg=0.11\n",
      "[1199 | 683.23] loss=0.06 avg=0.11\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " − 0.002,\n",
      "respectively. The chemoattractant, thus, stays in the domain for at least the total time,\n",
      "as it moves through the domain, but it also re-scales its position x in relation to the angle π/2\n",
      "0 ∈ S\n",
      "0 .\n",
      "(57)\n",
      "We have defined the chemoattractant in [36] with a measure of\n",
      "S\n",
      "0\n",
      "(ξ) = 1\n",
      "Γ\n",
      "S\n",
      "0\n",
      "(ξ) = 0. In particular, Γ\n",
      "S\n",
      "0\n",
      "(ξ) = 1\n",
      "Γ\n",
      "S\n",
      "0\n",
      "(ξ) = ηS\n",
      "1\n",
      "Γ\n",
      "S\n",
      "0\n",
      "(ξ) = η\n",
      "S\n",
      "1\n",
      "Γ\n",
      "S\n",
      "0\n",
      "(ξ) = 1\n",
      "Γ\n",
      "S\n",
      "0\n",
      "(ξ) = η\n",
      "S\n",
      "2\n",
      "Γ\n",
      "θ\n",
      "\n",
      "k(1,ξ)\n",
      "Z\n",
      "R+\n",
      "γq(λ)q(ξ + λk(k, v, vˆ)) dλ ψ(vˆ).\n",
      "Equation (50) indicates that the equilibrium distribution of the cells is a non-local average of the fibers distribution according to the sensing kernel γq\n",
      "9\n",
      "(ξ) = 0. The macroscopic behavior is strongly affected by the cell density, as\n",
      "when γq is high, cells migrate through the black market and, following the same migration,\n",
      "the diffusion coefficient. In general, the more fibers a cell has, the more efficiently it\n",
      "affects the local environment. However, a non-local sensing of the fibers distribution, even when\n",
      "the fibers distribution are set in motion by some external factor, can give a non-local\n",
      "average of the spatial distribution of fiber density to the fibers distribution alone. Therefore, the\n",
      "chemoattractant has to be able to determine the average of the two quantities ψ(vˆ) and ψ(θvˆ) in the distribution\n",
      "of the spatial velocity vˆ, in order to set the macroscopic limits. Moreover, the macroscopic density of the\n",
      "chemoattractant has to be slightly higher than the macroscopic skews, since the second\n",
      "time the macroscopic behavior is greatly affected by the cell density.\n",
      "The second scenario, referring to first scenario,, does not involve a huge\n",
      "amount of cells, as the chemoattractant can measure a microscopic detail and perform a microscopic\n",
      "dynamics in the neighborhood of the larger quantity. However, if the size of the\n",
      "chemoattractant is smaller than the macroscopic spatial radius, the behavior of the\n",
      "cell population can be greatly affected. For instance, in one embodiment, a small\n",
      "quantity in the spatial density of the fibers can determine the behavior of the\n",
      "cells, since a small quantity influences the behavior of the cells. Moreover, in a\n",
      "non-local sensing of the fibers, even if the fibers size are not important, one can consider\n",
      "setting the spatial limit to a microscopic level and, using that information, perform a microscopic\n",
      "dynamics analysis. For instance, in the present invention, the cell density can be measured\n",
      "in the neighborhood of the whole neighborhood scale, and the calculation made in the macroscopic\n",
      "distribution can be performed in a few parameters.\n",
      "BITCOIN\n",
      "The output of the cell generation is converted into a power level in bits per Volt (bps),\n",
      "and the cell cycle estimate is then modulated by the power of the input.\n",
      "BIG DIMENSION\n",
      "The cell cycle estimate can be used to quantify the most common of the many possible scenarios\n",
      "that can happen in a realistic cell environment. The factorization and the diffusive behavior\n",
      "in a simple many are some of the common scenarios that are illustrated in the description of the\n",
      "in. The description of the most common scenarios, in particular, refers to N = 9 in [p. 611], with p.\n",
      "Ω given in [39] for the measured macroscopic density. It is given by\n",
      "UT (x) = c(x)\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I1(k(x))\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I2(k(x))\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I2\n",
      "k\n",
      "I1(k(x))\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I2\n",
      "k\n",
      "I1(k(x))\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I2\n",
      "k\n",
      "I1(k(x))\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "I2\n",
      "\n",
      "\n",
      "[1200 | 694.28] loss=0.08 avg=0.11\n",
      "[1201 | 694.77] loss=0.17 avg=0.11\n",
      "[1202 | 695.23] loss=0.09 avg=0.11\n",
      "[1203 | 695.70] loss=0.04 avg=0.11\n",
      "[1204 | 696.17] loss=0.06 avg=0.11\n",
      "[1205 | 696.64] loss=0.06 avg=0.11\n",
      "[1206 | 697.11] loss=0.16 avg=0.11\n",
      "[1207 | 697.58] loss=0.12 avg=0.11\n",
      "[1208 | 698.05] loss=0.08 avg=0.11\n",
      "[1209 | 698.52] loss=0.06 avg=0.11\n",
      "[1210 | 699.00] loss=0.08 avg=0.11\n",
      "[1211 | 699.47] loss=0.08 avg=0.11\n",
      "[1212 | 699.94] loss=0.09 avg=0.11\n",
      "[1213 | 700.40] loss=0.08 avg=0.11\n",
      "[1214 | 700.87] loss=0.06 avg=0.11\n",
      "[1215 | 701.34] loss=0.09 avg=0.11\n",
      "[1216 | 701.81] loss=0.07 avg=0.11\n",
      "[1217 | 702.28] loss=0.05 avg=0.11\n",
      "[1218 | 702.75] loss=0.10 avg=0.11\n",
      "[1219 | 703.22] loss=0.11 avg=0.11\n",
      "[1220 | 703.70] loss=0.13 avg=0.11\n",
      "[1221 | 704.17] loss=0.05 avg=0.11\n",
      "[1222 | 704.63] loss=0.06 avg=0.11\n",
      "[1223 | 705.10] loss=0.10 avg=0.11\n",
      "[1224 | 705.57] loss=0.10 avg=0.11\n",
      "[1225 | 706.04] loss=0.08 avg=0.11\n",
      "[1226 | 706.51] loss=0.05 avg=0.11\n",
      "[1227 | 706.98] loss=0.14 avg=0.11\n",
      "[1228 | 707.44] loss=0.08 avg=0.11\n",
      "[1229 | 707.91] loss=0.09 avg=0.11\n",
      "[1230 | 708.38] loss=0.06 avg=0.10\n",
      "[1231 | 708.85] loss=0.08 avg=0.10\n",
      "[1232 | 709.33] loss=0.05 avg=0.10\n",
      "[1233 | 709.80] loss=0.07 avg=0.10\n",
      "[1234 | 710.27] loss=0.07 avg=0.10\n",
      "[1235 | 710.74] loss=0.23 avg=0.10\n",
      "[1236 | 711.21] loss=0.07 avg=0.10\n",
      "[1237 | 711.68] loss=0.05 avg=0.10\n",
      "[1238 | 712.15] loss=0.08 avg=0.10\n",
      "[1239 | 712.62] loss=0.09 avg=0.10\n",
      "[1240 | 713.09] loss=0.10 avg=0.10\n",
      "[1241 | 713.56] loss=0.09 avg=0.10\n",
      "[1242 | 714.03] loss=0.12 avg=0.10\n",
      "[1243 | 714.50] loss=0.08 avg=0.10\n",
      "[1244 | 714.96] loss=0.08 avg=0.10\n",
      "[1245 | 715.43] loss=0.11 avg=0.10\n",
      "[1246 | 715.90] loss=0.09 avg=0.10\n",
      "[1247 | 716.37] loss=0.08 avg=0.10\n",
      "[1248 | 716.85] loss=0.06 avg=0.10\n",
      "[1249 | 717.32] loss=0.13 avg=0.10\n",
      "[1250 | 717.79] loss=0.10 avg=0.10\n",
      "[1251 | 718.26] loss=0.14 avg=0.10\n",
      "[1252 | 718.73] loss=0.06 avg=0.10\n",
      "[1253 | 719.20] loss=0.07 avg=0.10\n",
      "[1254 | 719.67] loss=0.10 avg=0.10\n",
      "[1255 | 720.14] loss=0.05 avg=0.10\n",
      "[1256 | 720.62] loss=0.11 avg=0.10\n",
      "[1257 | 721.09] loss=0.08 avg=0.10\n",
      "[1258 | 721.56] loss=0.18 avg=0.10\n",
      "[1259 | 722.03] loss=0.13 avg=0.10\n",
      "[1260 | 722.50] loss=0.08 avg=0.10\n",
      "[1261 | 722.97] loss=0.06 avg=0.10\n",
      "[1262 | 723.44] loss=0.06 avg=0.10\n",
      "[1263 | 723.91] loss=0.06 avg=0.10\n",
      "[1264 | 724.38] loss=0.11 avg=0.10\n",
      "[1265 | 724.85] loss=0.07 avg=0.10\n",
      "[1266 | 725.32] loss=0.09 avg=0.10\n",
      "[1267 | 725.79] loss=0.08 avg=0.10\n",
      "[1268 | 726.26] loss=0.03 avg=0.10\n",
      "[1269 | 726.72] loss=0.06 avg=0.10\n",
      "[1270 | 727.19] loss=0.05 avg=0.10\n",
      "[1271 | 727.66] loss=0.06 avg=0.10\n",
      "[1272 | 728.13] loss=0.11 avg=0.10\n",
      "[1273 | 728.59] loss=0.07 avg=0.10\n",
      "[1274 | 729.07] loss=0.10 avg=0.10\n",
      "[1275 | 729.54] loss=0.06 avg=0.10\n",
      "[1276 | 730.01] loss=0.09 avg=0.10\n",
      "[1277 | 730.48] loss=0.06 avg=0.10\n",
      "[1278 | 730.95] loss=0.05 avg=0.10\n",
      "[1279 | 731.42] loss=0.05 avg=0.10\n",
      "[1280 | 731.89] loss=0.06 avg=0.10\n",
      "[1281 | 732.36] loss=0.09 avg=0.10\n",
      "[1282 | 732.83] loss=0.13 avg=0.10\n",
      "[1283 | 733.30] loss=0.05 avg=0.10\n",
      "[1284 | 733.77] loss=0.07 avg=0.10\n",
      "[1285 | 734.24] loss=0.10 avg=0.10\n",
      "[1286 | 734.72] loss=0.05 avg=0.10\n",
      "[1287 | 735.19] loss=0.04 avg=0.09\n",
      "[1288 | 735.66] loss=0.05 avg=0.09\n",
      "[1289 | 736.13] loss=0.10 avg=0.09\n",
      "[1290 | 736.60] loss=0.08 avg=0.09\n",
      "[1291 | 737.08] loss=0.04 avg=0.09\n",
      "[1292 | 737.55] loss=0.08 avg=0.09\n",
      "[1293 | 738.02] loss=0.08 avg=0.09\n",
      "[1294 | 738.49] loss=0.04 avg=0.09\n",
      "[1295 | 738.96] loss=0.04 avg=0.09\n",
      "[1296 | 739.43] loss=0.06 avg=0.09\n",
      "[1297 | 739.90] loss=0.08 avg=0.09\n",
      "[1298 | 740.37] loss=0.07 avg=0.09\n",
      "[1299 | 740.84] loss=0.06 avg=0.09\n",
      "Generating samples...\n",
      "======== SAMPLE 1 ========\n",
      " and the\n",
      "average of the two parameters. In particular, we shall consider a\n",
      "transition probability distribution\n",
      "p(x, v, vˆ) = p(x, v, vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(x + λvˆ) dλ dvˆ\n",
      "and\n",
      "γq(λ)S(x + λvˆ) dλ dvˆ ,\n",
      "both different from zero. In this case, we may choose\n",
      "γq(λ) = γS (λ)\n",
      "Z\n",
      "S\n",
      "d−1\n",
      "Z U\n",
      "0\n",
      "γq(λ)S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "γq(λ) S(x + λvˆ) dλ dvˆ\n",
      "c0\n",
      "Z\n",
      "R+\n",
      "γq(λ)S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "γS (λ) S(x + λvˆ) dλ dvˆ\n",
      "c1\n",
      "Z\n",
      "R+\n",
      "γq(λ) S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "γq(λ) S(x + λvˆ) dλ dvˆ\n",
      "c2\n",
      "Z\n",
      "R+\n",
      "γq(λ) S(x + λvˆ) dλ dvˆ\n",
      "+\n",
      "γq(λ) S(x + λvˆ) dλ dvˆ ,\n",
      "both different from zero. In this case, if γq = γS , on the one hand, and γS = γS = δuatedon, on the other hand, there is a\n",
      "preferential direction of motion × the diffusion tensor of the fibers distribution\n",
      "D\n",
      "0\n",
      "q\n",
      "(ξ) = DD¯ 0\n",
      "q\n",
      "(ξ) (∇S · vˆ)\n",
      "Z\n",
      "R+\n",
      "γS (λ)S(ξ + λvˆ) dλ dvˆ\n",
      "+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ ,\n",
      "both different from zero. In this case, if q(ξ, v, vˆ) were to hold, the sensing radius of the cell population\n",
      "60\n",
      "∇S\n",
      "S\n",
      " is given by\n",
      "c0\n",
      "ξ\n",
      "∇S\n",
      "S\n",
      "(ξ)\n",
      "Z\n",
      "R+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ\n",
      "+\n",
      "γS (λ) S(ξ + λvˆ) dλ dvˆ ,\n",
      " both different from zero.\n",
      "2.2 Prediction limits\n",
      "We now propose a practical implementation that, at the macroscopic level, approxides out a Dirac Delta for cell distribution of fiber orientation\n",
      "24.1\n",
      "Density-coupled polarization\n",
      "We assume that q is a Dirac Delta weighting\n",
      "Dq(x) = 1\n",
      "2\n",
      "q(x, vˆ) ⊗ vˆ\n",
      "∇S\n",
      "S . (ξ) takes into account the variation of directionality of the fibers\n",
      "∇S\n",
      "D\n",
      "0\n",
      "q(x, v, vˆ) vˆ = 1\n",
      "Γ\n",
      "Γ\n",
      "∇S\n",
      "S\n",
      ". (ξ)\n",
      "is the weighted-average of the two cues,\n",
      "antibody volume Dq(x) = 1\n",
      "Γ\n",
      "Γ\n",
      "∇S\n",
      "S\n",
      ", (ξ)\n",
      "is the mono-directional volume,\n",
      "that also has a moment per sense and\n",
      "Γ\n",
      "∇S\n",
      "S\n",
      ", (ξ)\n",
      "is the weighted-non-local average of the two cues,\n",
      "both differentiable in the domain Ω. (ξ)\n",
      "is a non-local average of the two cues,\n",
      "both differentiable in the fiber distribution R\n",
      "q(x, v, vˆ) = 1\n",
      "Γ\n",
      "q\n",
      "R\n",
      "(x)\n",
      "and\n",
      "Γ\n",
      "∇q\n",
      "S\n",
      ", (ξ)\n",
      "are the sensitivities. The fibers distributionally\n",
      "S\n",
      "ats the orientation of the cell\n",
      "Γ0\n",
      "q(x, v, vˆ)∇q · vˆ = 1\n",
      "Γ1\n",
      "q(x, v, vˆ)∇S\n",
      "S\n",
      ", (ξ)\n",
      "are the cells tensorities. The cell tensorities are representations of a non-local microscopic dynamics jump process,\n",
      "in which the cell\n",
      "\n",
      "[1300 | 751.99] loss=0.05 avg=0.09\n",
      "[1301 | 752.47] loss=0.09 avg=0.09\n",
      "interrupted\n",
      "Saving checkpoint/run1/model-1302\n"
     ]
    }
   ],
   "source": [
    "#@title Step 9:Training the Model\n",
    "#Model saved after 1000 steps\n",
    "import os # import after runtime is restarted\n",
    "os.chdir(\"/content/gpt-2/src/\")\n",
    "!python train.py --dataset out.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01ZDxuUoZ9aI"
   },
   "source": [
    "#Step 10: Creating a training model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-zAFd2hLQ2V"
   },
   "outputs": [],
   "source": [
    "#@title Step 10: Creating a Training Model directory\n",
    "#Creating a Training Model directory named 'tgmodel'\n",
    "import os\n",
    "run_dir = '/content/gpt-2/models/tgmodel'\n",
    "if not os.path.exists(run_dir):\n",
    "  os.makedirs(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-POx-g1Ql76C"
   },
   "outputs": [],
   "source": [
    "#@title Step 10A: Copying training Files\n",
    "!cp /content/gpt-2/src/checkpoint/run1/model-1000.data-00000-of-00001 /content/gpt-2/models/tgmodel\n",
    "!cp /content/gpt-2/src/checkpoint/run1/checkpoint /content/gpt-2/models/tgmodel\n",
    "!cp /content/gpt-2/src/checkpoint/run1/model-1000.index /content/gpt-2/models/tgmodel\n",
    "!cp /content/gpt-2/src/checkpoint/run1/model-1000.meta /content/gpt-2/models/tgmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdE9nNH8m7VD"
   },
   "outputs": [],
   "source": [
    "#@title Step 10B: Copying the OpenAI GPT-2 117M Model files\n",
    "!cp /content/gpt-2/models/117M/encoder.json /content/gpt-2/models/tgmodel\n",
    "!cp /content/gpt-2/models/117M/hparams.json /content/gpt-2/models/tgmodel\n",
    "!cp /content/gpt-2/models/117M/vocab.bpe /content/gpt-2/models/tgmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G8NOUXjMq4u"
   },
   "outputs": [],
   "source": [
    "#@title Step 10C: Renaming the model directories\n",
    "import os\n",
    "!mv /content/gpt-2/models/117M  /content/gpt-2/models/117M_OpenAI\n",
    "!mv /content/gpt-2/models/tgmodel  /content/gpt-2/models/117M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsL9VTMCD4VA"
   },
   "source": [
    "#Step 11: Generating unconditional samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3uexz_e4d18",
    "outputId": "e4b5497c-2eef-4e46-ae77-ee535e3aa2d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From generate_unconditional_samples.py:54: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-06-18 08:18:43.883508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-18 08:18:43.915370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:43.915943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-18 08:18:43.916246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:18:43.917680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-18 08:18:43.919193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-18 08:18:43.919508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-18 08:18:43.920967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-18 08:18:43.921667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-18 08:18:43.924492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-18 08:18:43.924610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:43.925215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:43.925724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-18 08:18:43.930283: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-06-18 08:18:43.930458: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55722a18f480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:18:43.930485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-18 08:18:44.123574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.124299: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55722a18fd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:18:44.124328: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-06-18 08:18:44.124491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.125053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-18 08:18:44.125118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:18:44.125158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-18 08:18:44.125178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-18 08:18:44.125198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-18 08:18:44.125220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-18 08:18:44.125238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-18 08:18:44.125257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-18 08:18:44.125326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.125876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.126450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-18 08:18:44.126519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:18:44.127772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-18 08:18:44.127799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-18 08:18:44.127809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-18 08:18:44.127925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.128517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:18:44.129041: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-18 08:18:44.129083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From generate_unconditional_samples.py:56: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From generate_unconditional_samples.py:65: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "2021-06-18 08:18:49.336695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "======================================== SAMPLE 1 ========================================\n",
      "\n",
      "These are by no means personnel pages — they're supposed to be notices to pastors and congregations that they are removing where the value of the 'structure' and 'eventual' construction isn't.\n",
      "\n",
      "Unfortunately, it's these pages that only serve to discredit, depending upon whom you ask.\n",
      "\n",
      "Most of the time, the sense result of doing everything wrong is a (mostly) broken sense. Right? That's one reason why so many pastors respond deferentially to critiques, blame others for living up to their reputations and are always disappointed by their own response. In other words, the larger the misunderstanding and negativity, the more there goes with you in dealing with signs and words.\n",
      "\n",
      "OK, good, let's move on to the trouble parts. Here, we'll apply the point of view of young adults to their church through the contexts they find themselves in the first place.\n",
      "\n",
      "Dr. John Pedrosin (Atlantic Regional Medical Center in Carlsbad, CA), a professor of mental health and behavior therapy at Washburn College who recently received his Masters degree from the State College of New Jersey and Ph.D. from St. Francis Sithero University in Lehigh, Minnesota, has been in ministry for seven and a half decades. He is a church volunteer at DeWitt's primate church in Spokane, Washington where he operates 24 hours a day and seven days a week.\n",
      "\n",
      "I can easily relate to Pedrosin's recollection of seeing Dr. Brian Hedges (Wellford Oaks, WI) perform surgical surgeries for a medical plant cardiac instrument in the early 1990s.\n",
      "\n",
      "Some of these events followed up with open and frank conversations with a forensic surgeon. Dr. Hedges became an ordained priest and a priest of Drlsoma with the provider, then began making his own patient debut at DeWitt's unlicensed primate church in Lehigh. Dr. Hedges's rookie experience allowed within Fasmon's Executive Director Melissa M Grolier live evangelization for Christians of all ages, persuading children of all ages that this high sanctity demonstrated how the truth came to pass as early in life as possible — and would guide Christians into daily living when looking into their past for answers.\n",
      "\n",
      "He was one of eight who had come to Teach Style Counseling for First Responder Tabbidists — a high sanctity event of course. This group of Wilfs supports community unconventional children's organizations, organizations that minister to abused children, and is supportive in unlicensed primate congregations — a whole other story that has potential to change current and future patient judgment.\n",
      "\n",
      "These protean doesn't appear quite as dedicated to local nonprofits. They've taught about and witnessed their own difficult side-by-side with religious clients and prayed at DeWitt's with them many times.\n",
      "\n",
      "Intersecting with such know up think tanks, primate associations, pastoral organizations from non-profit to chapel in various directions involved a lay ministry experience for several months; wearing black, he had just laid the groundwork for radical leadership at a span of enlightenment is what he is now inhabiting within us.\n",
      "\n",
      "\"One concern that I have going back and forth is little nursery rhymes, just like everyone people around here \" Peter Holley, professor of psychiatric psychiatry and behavioral sciences at University College London (Marymount Valley) Further Reading Correction: This piece was corrected December 17, 2016, when Peter Holley was added to the 2016 Assemblies of God among the claims the Skeptic Magazine is making about Ephem 100 Monastic Assembly Africa build out at Lake Mead in NC.<|endoftext|>There's a whole lot of new stuff on the way out of 2017 on Shopify. First off, it's all about the monetization mechanic. Ever since the and non-business category debuted with big bumps around the edges, a lot of concerns have popped up after growing demand themselves. In an effort to convince Amazon shoppers to source 90% of their sales through channels like Twitter and Rdio, Marketify began to try its hand at monetizing MFi.\n",
      "\n",
      "Just in case they tacked on, Shopify teamed up with TRBI. Launched by David Burch on August 31 and after multiple weeks of original concept builds they're kicking off a rollout on Aug. 10 with Shopping {N.D.}. Like everyone else, they hope to release Target Jabs on this week. He promised a fun way to make a virtual shopping experience.\n",
      "\n",
      "Reliable sources tell BroadbandView Retail, \"We have developed a premium store entrance payment system for U.S. men and women, based on the success of Deo Pearson's UNet Reading Demo Right Now, and also offering a new alternative to the retail and online marketing method developed by both companies.\" Marketify will also be joining that audience through Use Sales Partners like Pandoit and Dividend Marketplace. The retail program will be launched with Marketplace = money. They've also invested heavily into Network Disruption like Facebook Capital, Yinance, and\n",
      "Traceback (most recent call last):\n",
      "  File \"generate_unconditional_samples.py\", line 79, in <module>\n",
      "    fire.Fire(sample_model)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
      "    target=component.__name__)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "  File \"generate_unconditional_samples.py\", line 71, in sample_model\n",
      "    out = sess.run(output)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#@title Step 11: Generating Unconditional Samples\n",
    "import os # import after runtime is restarted\n",
    "os.chdir(\"/content/gpt-2/src\")\n",
    "!python generate_unconditional_samples.py --model_name '117M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM2-6u3WDyCw"
   },
   "source": [
    "#Step 12: Interactive context and completion examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HI7DuBK4iSU",
    "outputId": "cc675e5d-1254-48f7-bc6e-cc112fe947cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2021-06-18 08:19:21.830534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-18 08:19:21.859241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:21.859819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-18 08:19:21.860123: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:19:21.861514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-18 08:19:21.862937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-18 08:19:21.863276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-18 08:19:21.864637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-18 08:19:21.865325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-18 08:19:21.868258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-18 08:19:21.868387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:21.868974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:21.869508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-18 08:19:21.873849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
      "2021-06-18 08:19:21.874038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f7643b480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:19:21.874065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-06-18 08:19:22.071061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.071770: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x564f7643bd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-06-18 08:19:22.071800: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2021-06-18 08:19:22.071969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.072522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
      "pciBusID: 0000:00:04.0\n",
      "2021-06-18 08:19:22.072587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:19:22.072616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-06-18 08:19:22.072637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-18 08:19:22.072661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-18 08:19:22.072680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-06-18 08:19:22.072699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-06-18 08:19:22.072718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-18 08:19:22.072785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.073364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.073861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2021-06-18 08:19:22.073923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-06-18 08:19:22.075056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-18 08:19:22.075082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2021-06-18 08:19:22.075094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2021-06-18 08:19:22.075210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.075769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-18 08:19:22.076327: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2021-06-18 08:19:22.076371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Model prompt >>> During such processes, cells sense the environment and respond to external factors that induce a certain direction of motion towards specific targets (taxis): this results in a persistent migration in a certain preferential direction. The guidance cues leading to directed migration may be biochemical or biophysical. Biochemical cues can be, for example, soluble factors or growth factors that give rise to chemotaxis, which involves a mono-directional stimulus. Other cues generating mono-directional stimuli include, for instance, bound ligands to the substratum that induce haptotaxis, durotaxis, that involves migration towards regions with an increasing stiffness of the ECM, electrotaxis, also known as galvanotaxis, that prescribes a directed motion guided by an electric field or current, or phototaxis, referring to the movement oriented by a stimulus of light [34]. Important biophysical cues are some of the properties of the extracellular matrix (ECM), first among all the alignment of collagen fibers and its stiffness. In particular, the fiber alignment is shown to stimulate contact guidance [22, 21]. TL;DR:\n",
      "2021-06-18 08:28:14.573110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "======================================== SAMPLE 1 ========================================\n",
      " Do not allow the movement to be directed by a laser (i.e. a laser that only takes one pulse at a time), but rather a laser that is directed at a target and directed at a given direction. In a nutshell, be mindful\n",
      "================================================================================\n",
      "Model prompt >>> Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/contextlib.py\", line 130, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n",
      "    yield g\n",
      "  File \"interactive_conditional_samples.py\", line 73, in interact_model\n",
      "    raw_text = input(\"Model prompt >>> \")\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"interactive_conditional_samples.py\", line 91, in <module>\n",
      "    fire.Fire(interact_model)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 141, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 471, in _Fire\n",
      "    target=component.__name__)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/fire/core.py\", line 681, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "  File \"interactive_conditional_samples.py\", line 88, in interact_model\n",
      "    print(\"=\" * 80)\n",
      "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1633, in __exit__\n",
      "    close_thread.start()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 857, in start\n",
      "    self._started.wait()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 552, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#@title Step 12: Interactive Context and Completion Examples\n",
    "import os # import after runtime is restarted\n",
    "os.chdir(\"/content/gpt-2/src\")\n",
    "!python interactive_conditional_samples.py --temperature 0.8 --top_k 40 --model_name '117M' --length 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_nbFkH6Dg2Q"
   },
   "source": [
    "#Controlling Tokenized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihVnmXFYB-E7",
    "outputId": "d58eeffd-9af1-4298-ac25-8fa954028a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212 5644  326 ...   13  198 2682]\n",
      "(29379,)\n",
      "1212\n",
      "5644\n",
      "326\n",
      "11\n",
      "355\n",
      "716\n",
      "78\n",
      "1765\n",
      "1868\n",
      "4778\n",
      "Converting the JSON encoded data into a Python dictionary\n",
      "! : 0\n",
      "\" : 1\n",
      "# : 2\n",
      "$ : 3\n",
      "% : 4\n",
      "& : 5\n",
      "' : 6\n",
      "( : 7\n",
      ") : 8\n",
      "* : 9\n",
      "This : 1212\n",
      "Ġsuggests : 5644\n",
      "Ġthat : 326\n",
      ", : 11\n",
      "Ġas : 355\n",
      "Ġam : 716\n",
      "o : 78\n",
      "eb : 1765\n",
      "oid : 1868\n",
      "Ġcells : 4778\n",
      "Ġare : 389\n",
      "Ġless : 1342\n",
      "Ġcontract : 2775\n",
      "ile : 576\n",
      ", : 11\n",
      "Ġwhile : 981\n",
      "Ġmes : 18842\n",
      "ench : 24421\n",
      "ym : 4948\n",
      "al : 282\n",
      "Ċ : 198\n",
      "cells : 46342\n",
      "Ġare : 389\n",
      "Ġmore : 517\n",
      "Ġcontract : 2775\n",
      "ile : 576\n",
      ", : 11\n",
      "Ġand : 290\n",
      "Ġthere : 612\n",
      "Ġmay : 743\n",
      "Ġbe : 307\n",
      "Ġa : 257\n",
      "Ġswitching : 15430\n",
      "Ġbetween : 1022\n",
      "Ġam : 716\n",
      "o : 78\n",
      "eb : 1765\n",
      "oid : 1868\n",
      "Ġand : 290\n",
      "Ġmes : 18842\n",
      "ench : 24421\n",
      "ym : 4948\n",
      "al : 282\n",
      "Ċ : 198\n",
      "m : 76\n",
      "igration : 4254\n",
      ", : 11\n",
      "Ġperhaps : 3737\n",
      "Ġthere : 612\n",
      "Ġcan : 460\n",
      "Ġalso : 635\n",
      "Ġbe : 307\n",
      "Ġa : 257\n",
      "Ġswitching : 15430\n",
      "Ġbetween : 1022\n",
      "Ġthe : 262\n",
      "Ġdominance : 18648\n",
      "Ġof : 286\n",
      "Ġchem : 4607\n",
      "ot : 313\n",
      "axis : 22704\n",
      "Ġ( : 357\n",
      "amo : 18811\n",
      "eb : 1765\n",
      "oid : 1868\n",
      "Ċ : 198\n",
      "m : 76\n",
      "igration : 4254\n",
      ") : 8\n",
      "Ġand : 290\n",
      "Ġcontact : 2800\n",
      "Ġguidance : 11154\n",
      "Ġ( : 357\n",
      "mes : 6880\n",
      "ench : 24421\n",
      "ym : 4948\n",
      "al : 282\n",
      "Ġmigration : 13472\n",
      ") : 8\n",
      "Ġ[ : 685\n",
      "60 : 1899\n",
      "]. : 4083\n",
      "ĠOne : 1881\n",
      "Ġof : 286\n",
      "Ġthe : 262\n",
      "Ġmost : 749\n",
      "Ġinteresting : 3499\n",
      "Ġ2 : 362\n",
      "D : 35\n",
      "Ċ : 198\n",
      "platform : 24254\n",
      "s : 82\n",
      ", : 11\n",
      "Ġallowing : 5086\n",
      "Ġto : 284\n",
      "Ġstudy : 2050\n",
      "Ġcontact : 2800\n",
      "Ġguidance : 11154\n",
      "Ġand : 290\n",
      "Ġchem : 4607\n",
      "ot : 313\n",
      "axis : 22704\n",
      ", : 11\n",
      "Ġwas : 373\n",
      "Ġproposed : 5150\n",
      "Ġin : 287\n",
      "Ġ[ : 685\n",
      "57 : 3553\n",
      "], : 4357\n",
      "Ġin : 287\n",
      "Ġwhich : 543\n",
      "Ġthe : 262\n",
      "Ċ : 198\n",
      "authors : 41617\n",
      "Ġdemonstrated : 9555\n",
      "Ġan : 281\n",
      "Ġadditive : 38298\n",
      "Ġeffect : 1245\n",
      "Ġof : 286\n",
      "Ġchemical : 5931\n",
      "Ġgrad : 3915\n",
      "ients : 2334\n",
      "Ġand : 290\n",
      "Ġfiber : 13608\n",
      "Ġalignment : 19114\n",
      "Ġby : 416\n",
      "Ġmeasuring : 15964\n",
      "Ċ : 198\n",
      "the : 1169\n",
      "Ġpersistence : 30802\n",
      "Ġtime : 640\n",
      "; : 26\n",
      "Ġthey : 484\n",
      "Ġalso : 635\n",
      "Ġobserved : 6515\n",
      "Ġthat : 326\n",
      "Ġcells : 4778\n",
      "Ġwere : 547\n",
      "Ġdirected : 7924\n",
      "Ġby : 416\n",
      "Ġfiber : 13608\n",
      "Ġalignment : 19114\n",
      "Ġand : 290\n",
      "Ġthere : 612\n",
      "Ġwas : 373\n",
      "Ċ : 198\n",
      "no : 3919\n",
      "Ġeffect : 1245\n",
      "Ġof : 286\n",
      "Ġthe : 262\n",
      "Ġchemical : 5931\n",
      "Ġgradient : 31312\n",
      "Ġwhen : 618\n",
      "Ġfibers : 26742\n",
      "Ġwere : 547\n",
      "Ġaligned : 19874\n",
      "Ġperpendicular : 47190\n",
      "Ġto : 284\n",
      "Ġit : 340\n",
      ". : 13\n",
      "ĠA : 317\n",
      "Ġsimilar : 2092\n",
      "Ġsetting : 4634\n",
      "Ċ : 198\n",
      "was : 9776\n",
      "Ġalso : 635\n",
      "Ġused : 973\n",
      "Ġfor : 329\n",
      "Ġstudying : 11065\n",
      "Ġthe : 262\n",
      "Ġdependence : 21403\n",
      "Ġof : 286\n",
      "Ġcontact : 2800\n",
      "Ġguidance : 11154\n",
      "Ġon : 319\n",
      "Ġthe : 262\n",
      "Ġcell : 2685\n",
      "Ġcycle : 6772\n",
      "Ġ[ : 685\n",
      "48 : 2780\n",
      "]. : 4083\n",
      "ĠHowever : 2102\n",
      ", : 11\n",
      "ĠIn : 554\n",
      "Ċ : 198\n",
      "the : 1169\n",
      "Ġcase : 1339\n",
      "Ġof : 286\n",
      "Ġdifferent : 1180\n",
      "Ġmulti : 5021\n",
      "- : 12\n",
      "direction : 37295\n",
      "al : 282\n",
      "Ġcues : 25288\n",
      ", : 11\n",
      "Ġtotally : 6635\n",
      "Ġdifferent : 1180\n",
      "Ġscenarios : 13858\n",
      "Ġmay : 743\n",
      "Ġhappen : 1645\n",
      ", : 11\n",
      "Ġe : 304\n",
      ". : 13\n",
      "g : 70\n",
      ". : 13\n",
      "Ġin : 287\n",
      "Ġ[ : 685\n",
      "51 : 4349\n",
      "] : 60\n",
      "Ġit : 340\n",
      "Ġis : 318\n",
      "Ċ : 198\n",
      "shown : 42579\n",
      "Ġthat : 326\n",
      "Ġfor : 329\n",
      "Ġcontact : 2800\n",
      "Ġguidance : 11154\n",
      "Ġand : 290\n",
      "Ġelect : 1742\n",
      "rot : 10599\n",
      "axis : 22704\n",
      "Ġin : 287\n",
      "Ġthe : 262\n",
      "Ġcor : 1162\n",
      "nea : 39718\n",
      ", : 11\n",
      "Ġelect : 1742\n",
      "rot : 10599\n",
      "axis : 22704\n",
      "Ġwins : 7864\n",
      "Ġwhen : 618\n",
      "Ġcompeting : 11780\n",
      "Ċ : 198\n",
      "with : 4480\n",
      "Ġthe : 262\n",
      "Ġdirection : 4571\n",
      "Ġof : 286\n",
      "Ġalignment : 19114\n",
      "Ġof : 286\n",
      "Ġthe : 262\n",
      "Ġfibers : 26742\n",
      ". : 13\n",
      "Ċ : 198\n",
      "Multi : 29800\n",
      "- : 12\n",
      "cue : 15509\n",
      "Ġkinetic : 37892\n",
      "Ġmodel : 2746\n",
      "Ġwith : 351\n",
      "Ġnon : 1729\n",
      "- : 12\n",
      "local : 12001\n",
      "Ġsensing : 34244\n",
      "Ġfor : 329\n",
      "Ġcell : 2685\n",
      "Ċ : 198\n",
      "m : 76\n",
      "igration : 4254\n",
      "Ġon : 319\n",
      "Ġa : 257\n",
      "Ġfibers : 26742\n",
      "Ġnetwork : 3127\n",
      "Ġwith : 351\n",
      "Ġchem : 4607\n",
      "ot : 313\n",
      "axis : 22704\n",
      "Ċ : 198\n",
      "Mart : 13143\n",
      "ina : 1437\n",
      "ĠCon : 1482\n",
      "te : 660\n",
      "ĠâĪ : 18872\n",
      "Ĺ : 245\n",
      "ĠNad : 21877\n",
      "ia : 544\n",
      "ĠL : 406\n",
      "oy : 726\n",
      "ĠâĢ : 564\n",
      "ł : 254\n",
      "âĢ : 447\n",
      "¡ : 94\n",
      "Ċ : 198\n",
      "June : 15749\n",
      "Ġ18 : 1248\n",
      ", : 11\n",
      "Ġ2020 : 12131\n",
      "Ċ : 198\n",
      "Abstract : 23839\n",
      "Ċ : 198\n",
      "C : 34\n",
      "ells : 19187\n",
      "Ġperform : 1620\n",
      "Ġdirected : 7924\n",
      "Ġmotion : 6268\n",
      "Ġin : 287\n",
      "Ġresponse : 2882\n",
      "Ġto : 284\n",
      "Ġexternal : 7097\n",
      "Ġstimuli : 25973\n",
      "Ġthat : 326\n",
      "Ġthey : 484\n",
      "Ġdetect : 4886\n",
      "Ġby : 416\n",
      "Ġsensing : 34244\n",
      "Ċ : 198\n",
      "the : 1169\n",
      "Ġenvironment : 2858\n",
      "Ġwith : 351\n",
      "Ġtheir : 511\n",
      "Ġmembrane : 25019\n",
      "Ġprot : 1237\n",
      "rus : 14932\n",
      "ions : 507\n",
      ". : 13\n",
      "ĠIn : 554\n",
      "Ġparticular : 1948\n",
      ", : 11\n",
      "Ġseveral : 1811\n",
      "Ġbiochemical : 47685\n",
      "Ġand : 290\n",
      "Ġbi : 3182\n",
      "ophysical : 41789\n",
      "Ġcues : 25288\n",
      "Ġgive : 1577\n",
      "Ġrise : 4485\n",
      "Ġto : 284\n",
      "Ġtactic : 18543\n",
      "Ġmigration : 13472\n",
      "Ġin : 287\n",
      "Ġthe : 262\n",
      "Ġdirection : 4571\n",
      "Ġof : 286\n",
      "Ġtheir : 511\n",
      "Ġspecific : 2176\n",
      "Ġtargets : 6670\n",
      ". : 13\n",
      "ĠThis : 770\n",
      "Ġdefines : 15738\n",
      "Ċ : 198\n",
      "a : 64\n",
      "Ġmulti : 5021\n",
      "- : 12\n",
      "cue : 15509\n",
      "Ġenvironment : 2858\n",
      "Ġin : 287\n",
      "Ġwhich : 543\n",
      "Ġcells : 4778\n",
      "Ġhave : 423\n",
      "Ġto : 284\n",
      "Ġsort : 3297\n",
      "Ġand : 290\n",
      "Ġcombine : 12082\n",
      "Ġdifferent : 1180\n",
      ", : 11\n",
      "Ġand : 290\n",
      "Ġpotentially : 6196\n",
      "Ċ : 198\n",
      "competitive : 46131\n",
      ", : 11\n",
      "Ġstimuli : 25973\n",
      ". : 13\n",
      "ĠWe : 775\n",
      "Ġpropose : 18077\n",
      "Ġa : 257\n",
      "Ġnon : 1729\n",
      "- : 12\n",
      "local : 12001\n",
      "Ġkinetic : 37892\n",
      "Ġmodel : 2746\n",
      "Ġfor : 329\n",
      "Ġcell : 2685\n",
      "Ġmigration : 13472\n",
      "Ġin : 287\n",
      "Ġpresence : 4931\n",
      "Ġof : 286\n",
      "Ċ : 198\n",
      "two : 11545\n",
      "Ġexternal : 7097\n",
      "Ġfactors : 5087\n",
      "Ġboth : 1111\n",
      "Ġinfluencing : 32596\n",
      "Ġcell : 2685\n",
      "Ġpolarization : 42704\n",
      ": : 25\n",
      "Ġcontact : 2800\n",
      "Ġguidance : 11154\n",
      "Ġand : 290\n",
      "Ġchem : 4607\n",
      "ot : 313\n",
      "axis : 22704\n",
      ". : 13\n",
      "ĠWe : 775\n",
      "Ċ : 198\n",
      "pro : 1676\n",
      "pose : 3455\n",
      "Ġtwo : 734\n",
      "Ġdifferent : 1180\n",
      "Ġsensing : 34244\n",
      "Ġstrategies : 10064\n",
      "Ġand : 290\n",
      "Ġwe : 356\n",
      "Ġanalyze : 16602\n",
      "Ġthe : 262\n",
      "Ġtwo : 734\n",
      "Ġresulting : 7186\n",
      "Ġmodels : 4981\n",
      "Ġby : 416\n",
      "Ġrecovering : 20222\n",
      "Ċ : 198\n",
      "the : 1169\n",
      "Ġappropriate : 5035\n",
      "Ġmacro : 15021\n",
      "sc : 1416\n",
      "opic : 16603\n",
      "Ġlimit : 4179\n",
      "Ġin : 287\n",
      "Ġdifferent : 1180\n",
      "Ġregimes : 25879\n",
      ", : 11\n",
      "Ġin : 287\n",
      "Ġorder : 1502\n",
      "Ġto : 284\n",
      "Ġsee : 766\n",
      "Ġhow : 703\n",
      "Ġthe : 262\n",
      "Ġsize : 2546\n",
      "Ġof : 286\n",
      "Ġthe : 262\n",
      "Ġcell : 2685\n",
      ", : 11\n",
      "Ċ : 198\n",
      "with : 4480\n",
      "Ġrespect : 2461\n",
      "Ġto : 284\n",
      "Ġthe : 262\n",
      "Ġvariation : 12291\n",
      "Ġof : 286\n",
      "Ġboth : 1111\n",
      "Ġexternal : 7097\n",
      "Ġfields : 7032\n",
      ", : 11\n",
      "Ġinfluences : 16717\n",
      "Ġthe : 262\n",
      "Ġoverall : 4045\n",
      "Ġbehavior : 4069\n",
      ". : 13\n",
      "ĠMoreover : 10968\n",
      ", : 11\n",
      "Ċ : 198\n",
      "we : 732\n",
      "Ġintegrate : 19386\n",
      "Ġnumer : 5470\n",
      "ically : 1146\n",
      "Ġthe : 262\n",
      "Ġkinetic : 37892\n",
      "Ġtransport : 4839\n",
      "Ġequation : 16022\n",
      "Ġin : 287\n",
      "Ġa : 257\n",
      "Ġtwo : 734\n",
      "- : 12\n",
      "dimensional : 19577\n",
      "Ġsetting : 4634\n",
      "Ġin : 287\n",
      "Ġorder : 1502\n",
      "Ċ : 198\n",
      "to : 1462\n",
      "Ġinvestigate : 9161\n",
      "Ġqual : 4140\n",
      "itatively : 48668\n",
      "Ġvarious : 2972\n",
      "Ġscenarios : 13858\n",
      ". : 13\n",
      "Ċ : 198\n",
      "Key : 9218\n",
      "word : 4775\n",
      ". : 13\n",
      "ĠKin : 16645\n",
      "etic : 5139\n",
      "Ġequations : 27490\n",
      ", : 11\n",
      "Ġmult : 1963\n",
      "isc : 2304\n",
      "ale : 1000\n",
      "Ġmodeling : 21128\n",
      ", : 11\n",
      "Ġmulti : 5021\n",
      "- : 12\n",
      "cue : 15509\n",
      ", : 11\n",
      "Ġnon : 1729\n",
      "- : 12\n",
      "local : 12001\n",
      ", : 11\n",
      "Ġhyd : 7409\n",
      "rod : 14892\n",
      "ynamic : 28995\n",
      "Ġlimit : 4179\n",
      ", : 11\n",
      "Ċ : 198\n"
     ]
    }
   ],
   "source": [
    "#@title Additional Tools: Controlling Tokenized Data\n",
    "#Unzip out.npz\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/content/gpt-2/src/out.npz', 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/gpt-2/src/')\n",
    "\n",
    "#Load arr_0.npy which contains encoded dset\n",
    "import numpy as np\n",
    "f=np.load('/content/gpt-2/src/arr_0.npy')\n",
    "print(f)\n",
    "print(f.shape)\n",
    "for i in range(0,10):\n",
    "    print(f[i])\n",
    "     \n",
    "#We first import encoder.json\n",
    "import json\n",
    "i=0\n",
    "with open(\"/content/gpt-2/models/117M/encoder.json\", \"r\") as read_file:\n",
    "    print(\"Converting the JSON encoded data into a Python dictionary\")\n",
    "    developer = json.load(read_file) #converts the encoded data into a Python dictionary\n",
    "    for key, value in developer.items(): #we parse the decoded json data\n",
    "        i+=1\n",
    "        if(i>10):\n",
    "            break;\n",
    "        print(key, \":\", value)\n",
    "\n",
    "#We will now search for the key and value for each encoded token\n",
    "    for i in range(0,500):\n",
    "        for key, value in developer.items():\n",
    "            if f[i]==value:\n",
    "                print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime = time.time()\n",
    "elapsedTime = time.strftime(\"%H:%M:%S\", time.gmtime(endTime - startTime))\n",
    "\n",
    "print(todaysDate.strftime('# Run Date: %A, %B %d, %Y'))\n",
    "print(f\"# Run Time: {elapsedTime}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Training OpenAI GPT-2-CH09.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
